{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "344a49cd",
   "metadata": {},
   "source": [
    "# 03 - Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b067a25",
   "metadata": {},
   "source": [
    "In this notebook, we begin the modeling phase of the Store Sales - Time Series Forecasting project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5832a",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "The primary objective of this phase is to develop and evaluate models that can accurately predict daily sales for each store and product family.\n",
    "\n",
    "- Focus on two modeling approaches:\n",
    "    - **Prophet:** To capture seasonality and trend effects in the sales data.\n",
    "    - **XGBoost:** To leverage engineered features such as lagged sales and promotions, as well as categorical variables.\n",
    "- Limit the scope to a select set of well-performing models, balancing predictive accuracy with interpretability and practical application.\n",
    "- Apply basic hyperparameter tuning (randomized or grid search) to optimize model performance where feasible.\n",
    "- Use the RMSLE metric as a consistent benchmark for model evaluation, aligning with competition standards and business needs.\n",
    "- Maintain a manageable modeling scope given time constraints, ensuring results are reproducible, explainable, and actionable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b9f6a",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09be44f9",
   "metadata": {},
   "source": [
    "### Data Import and Type Specification\n",
    "\n",
    "In this section, we import the preprocessed training dataset generated during the data preparation phase.  \n",
    "To ensure efficient memory usage and compatibility with downstream modeling (especially with libraries like XGBoost), we explicitly specify the data types of key categorical columns (`family`, `city`, `state`, `type`) as `category`.  \n",
    "Event- and holiday-related columns (`type_holiday`, `locale`, `locale_name`, `description`, `transferred`) are set as `object` type to avoid issues with mixed data types and to accommodate their sparse, textual nature.\n",
    "\n",
    "We also run a quick check to verify the dataâ€™s shape, column names, missing values, and data types before proceeding with further modeling steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c19ebefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3054348, 37)\n",
      "Columns: ['id', 'date', 'store_nbr', 'family', 'sales', 'onpromotion', 'is_sales_outlier', 'transactions_x', 'is_transactions_outlier', 'day', 'month', 'year', 'week', 'weekday', 'is_weekend', 'is_holiday', 'high_promo', 'sales_lag_1', 'sales_lag_7', 'sales_lag_14', 'sales_lag_28', 'sales_rolling_7', 'sales_rolling_14', 'sales_rolling_28', 'sales_rolling_30', 'sales_rolling_90', 'city', 'state', 'type', 'cluster', 'type_holiday', 'locale', 'locale_name', 'description', 'transferred', 'transactions_y', 'dcoilwtico']\n",
      "Missing values:\n",
      " id                               0\n",
      "date                             0\n",
      "store_nbr                        0\n",
      "family                           0\n",
      "sales                            0\n",
      "onpromotion                      0\n",
      "is_sales_outlier                 0\n",
      "transactions_x              249117\n",
      "is_transactions_outlier          0\n",
      "day                              0\n",
      "month                            0\n",
      "year                             0\n",
      "week                             0\n",
      "weekday                          0\n",
      "is_weekend                       0\n",
      "is_holiday                       0\n",
      "high_promo                       0\n",
      "sales_lag_1                   1782\n",
      "sales_lag_7                  12474\n",
      "sales_lag_14                 24948\n",
      "sales_lag_28                 49896\n",
      "sales_rolling_7               1782\n",
      "sales_rolling_14              1782\n",
      "sales_rolling_28              1782\n",
      "sales_rolling_30              1782\n",
      "sales_rolling_90              1782\n",
      "city                             0\n",
      "state                            0\n",
      "type                             0\n",
      "cluster                          0\n",
      "type_holiday               2551824\n",
      "locale                     2551824\n",
      "locale_name                2551824\n",
      "description                2551824\n",
      "transferred                2551824\n",
      "transactions_y              249117\n",
      "dcoilwtico                       0\n",
      "dtype: int64\n",
      "Data types:\n",
      " id                                  int64\n",
      "date                       datetime64[ns]\n",
      "store_nbr                           int64\n",
      "family                           category\n",
      "sales                             float64\n",
      "onpromotion                         int64\n",
      "is_sales_outlier                     bool\n",
      "transactions_x                    float64\n",
      "is_transactions_outlier              bool\n",
      "day                                 int64\n",
      "month                               int64\n",
      "year                                int64\n",
      "week                                int64\n",
      "weekday                             int64\n",
      "is_weekend                          int64\n",
      "is_holiday                          int64\n",
      "high_promo                          int64\n",
      "sales_lag_1                       float64\n",
      "sales_lag_7                       float64\n",
      "sales_lag_14                      float64\n",
      "sales_lag_28                      float64\n",
      "sales_rolling_7                   float64\n",
      "sales_rolling_14                  float64\n",
      "sales_rolling_28                  float64\n",
      "sales_rolling_30                  float64\n",
      "sales_rolling_90                  float64\n",
      "city                             category\n",
      "state                            category\n",
      "type                             category\n",
      "cluster                             int64\n",
      "type_holiday                       object\n",
      "locale                             object\n",
      "locale_name                        object\n",
      "description                        object\n",
      "transferred                        object\n",
      "transactions_y                    float64\n",
      "dcoilwtico                        float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>is_sales_outlier</th>\n",
       "      <th>transactions_x</th>\n",
       "      <th>is_transactions_outlier</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>high_promo</th>\n",
       "      <th>sales_lag_1</th>\n",
       "      <th>sales_lag_7</th>\n",
       "      <th>sales_lag_14</th>\n",
       "      <th>sales_lag_28</th>\n",
       "      <th>sales_rolling_7</th>\n",
       "      <th>sales_rolling_14</th>\n",
       "      <th>sales_rolling_28</th>\n",
       "      <th>sales_rolling_30</th>\n",
       "      <th>sales_rolling_90</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>type_holiday</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "      <th>transactions_y</th>\n",
       "      <th>dcoilwtico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       date  store_nbr      family  sales  onpromotion  is_sales_outlier  \\\n",
       "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0             False   \n",
       "1   1 2013-01-01          1   BABY CARE    0.0            0             False   \n",
       "2   2 2013-01-01          1      BEAUTY    0.0            0             False   \n",
       "3   3 2013-01-01          1   BEVERAGES    0.0            0             False   \n",
       "4   4 2013-01-01          1       BOOKS    0.0            0             False   \n",
       "\n",
       "   transactions_x  is_transactions_outlier  day  month  year  week  weekday  \\\n",
       "0             NaN                    False    1      1  2013     1        1   \n",
       "1             NaN                    False    1      1  2013     1        1   \n",
       "2             NaN                    False    1      1  2013     1        1   \n",
       "3             NaN                    False    1      1  2013     1        1   \n",
       "4             NaN                    False    1      1  2013     1        1   \n",
       "\n",
       "   is_weekend  is_holiday  high_promo  sales_lag_1  sales_lag_7  sales_lag_14  \\\n",
       "0           0           1           0          NaN          NaN           NaN   \n",
       "1           0           1           0          NaN          NaN           NaN   \n",
       "2           0           1           0          NaN          NaN           NaN   \n",
       "3           0           1           0          NaN          NaN           NaN   \n",
       "4           0           1           0          NaN          NaN           NaN   \n",
       "\n",
       "   sales_lag_28  sales_rolling_7  sales_rolling_14  sales_rolling_28  \\\n",
       "0           NaN              NaN               NaN               NaN   \n",
       "1           NaN              NaN               NaN               NaN   \n",
       "2           NaN              NaN               NaN               NaN   \n",
       "3           NaN              NaN               NaN               NaN   \n",
       "4           NaN              NaN               NaN               NaN   \n",
       "\n",
       "   sales_rolling_30  sales_rolling_90   city      state type  cluster  \\\n",
       "0               NaN               NaN  Quito  Pichincha    D       13   \n",
       "1               NaN               NaN  Quito  Pichincha    D       13   \n",
       "2               NaN               NaN  Quito  Pichincha    D       13   \n",
       "3               NaN               NaN  Quito  Pichincha    D       13   \n",
       "4               NaN               NaN  Quito  Pichincha    D       13   \n",
       "\n",
       "  type_holiday    locale locale_name         description transferred  \\\n",
       "0      Holiday  National     Ecuador  Primer dia del ano       False   \n",
       "1      Holiday  National     Ecuador  Primer dia del ano       False   \n",
       "2      Holiday  National     Ecuador  Primer dia del ano       False   \n",
       "3      Holiday  National     Ecuador  Primer dia del ano       False   \n",
       "4      Holiday  National     Ecuador  Primer dia del ano       False   \n",
       "\n",
       "   transactions_y  dcoilwtico  \n",
       "0             NaN       93.14  \n",
       "1             NaN       93.14  \n",
       "2             NaN       93.14  \n",
       "3             NaN       93.14  \n",
       "4             NaN       93.14  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Path to processed data\n",
    "DATA_PATH = \"../data/processed/train_prepared.csv\"\n",
    "\n",
    "# Specify categorical columns on import\n",
    "dtype_dict = {\n",
    "    'family': 'category',\n",
    "    'city': 'category',\n",
    "    'state': 'category',\n",
    "    'type': 'category',\n",
    "    'type_holiday': 'object',\n",
    "    'locale': 'object',\n",
    "    'locale_name': 'object',\n",
    "    'description': 'object',\n",
    "    'transferred': 'object'\n",
    "}\n",
    "\n",
    "# Load data with specified dtypes\n",
    "df = pd.read_csv(\n",
    "    DATA_PATH,\n",
    "    parse_dates=['date'],\n",
    "    dtype=dtype_dict\n",
    ")\n",
    "\n",
    "# Quick checks\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "print(\"Data types:\\n\", df.dtypes)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef07ff6",
   "metadata": {},
   "source": [
    "### Data Verification Summary\n",
    "\n",
    "A quick inspection of the imported dataset confirms that all columns have been loaded as expected, with appropriate data types for modeling and analysis.  \n",
    "- **Shape:** The dataset includes over 3 million rows and 37 columns, matching expectations from earlier processing steps.\n",
    "- **Column Presence:** All key featuresâ€”ranging from sales and promotions to engineered lag/rolling statistics and event indicatorsâ€”are present.\n",
    "- **Missing Values:** Most core features (such as sales, dates, and categorical identifiers) are complete. Missing values are only present in certain engineered features (e.g., rolling/lags near the start of the time series), sparse holiday-related columns, and some transaction data. These are either expected or will be handled during modeling.\n",
    "- **Data Types:** Categorical columns are correctly typed, while numerical and boolean columns are appropriately formatted. Sparse event-related columns remain as `object` types to allow flexible handling in downstream steps.\n",
    "\n",
    "These checks ensure that the dataset is ready for robust modeling and that all necessary information has been successfully carried forward from the data preparation phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fb8312",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31163678",
   "metadata": {},
   "source": [
    "To robustly evaluate model performance, we split the data chronologically.  \n",
    "We use all data before `2016-08-16` for training, and reserve the period from `2016-08-16` onward as the validation set.  \n",
    "This validation period covers a full year, allowing us to assess the modelâ€™s ability to capture seasonality, trends, and event effects across different times of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf7d55eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2395008, 37)\n",
      "Validation shape: (659340, 37)\n",
      "Train date range: 2013-01-01 00:00:00 to 2016-08-15 00:00:00\n",
      "Validation date range: 2016-08-16 00:00:00 to 2017-08-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Define split date for validation\n",
    "split_date = '2016-08-16'\n",
    "\n",
    "# Chronological split\n",
    "train_df = df[df['date'] < split_date].copy()\n",
    "valid_df = df[df['date'] >= split_date].copy()\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Validation shape:\", valid_df.shape)\n",
    "print(\"Train date range:\", train_df['date'].min(), \"to\", train_df['date'].max())\n",
    "print(\"Validation date range:\", valid_df['date'].min(), \"to\", valid_df['date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028fa295",
   "metadata": {},
   "source": [
    "## Baseline Naive Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56abd2",
   "metadata": {},
   "source": [
    "Before fitting advanced models, we establish a simple baseline for sales forecasting.  \n",
    "The **Naive Forecast** predicts sales in the validation period using the last observed value for each (store, family) in the training data.  \n",
    "This provides a reference for model evaluationâ€”if advanced models do not outperform the naive approach, they offer limited value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "487e2904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Naive) RMSLE: 0.9765\n"
     ]
    }
   ],
   "source": [
    "# For each (store_nbr, family), get the last sales value in the training set\n",
    "last_sales = (\n",
    "    train_df\n",
    "    .sort_values(['store_nbr', 'family', 'date'])\n",
    "    .groupby(['store_nbr', 'family'], observed=True)['sales']  # Explicit\n",
    "    .last()\n",
    "    .reset_index()\n",
    "    .rename(columns={'sales': 'last_sales'})\n",
    ")\n",
    "\n",
    "# Merge this 'last_sales' back onto the validation set\n",
    "valid_pred = valid_df.merge(\n",
    "    last_sales,\n",
    "    on=['store_nbr', 'family'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Baseline prediction: last known sales\n",
    "valid_pred['sales_pred'] = valid_pred['last_sales']\n",
    "\n",
    "# If no last sales is found (e.g., new (store, family)), fillna with 0 or median\n",
    "valid_pred['sales_pred'] = valid_pred['sales_pred'].fillna(0)\n",
    "\n",
    "# Evaluate RMSLE\n",
    "rmsle = np.sqrt(\n",
    "    mean_squared_log_error(valid_pred['sales'], valid_pred['sales_pred'])\n",
    ")\n",
    "\n",
    "print(f\"Baseline (Naive) RMSLE: {rmsle:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe41db",
   "metadata": {},
   "source": [
    "## Prophet Baseline Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea07cea0",
   "metadata": {},
   "source": [
    "To establish a robust time series baseline, I applied Prophet to forecast sales for each (store, family) combination independently. Prophet is well-suited for this use case, as it can automatically capture complex patterns such as trend shifts, seasonality, and the influence of holidaysâ€”making it an excellent tool for quick prototyping and exploratory forecasting.\n",
    "\n",
    "**Why train Prophet per (store, family)?**  \n",
    "Forecasting at this level of granularity respects the distinct sales patterns of different product families and locations, ensuring a fair and interpretable benchmark for more complex models.\n",
    "\n",
    "**Why export detailed results?**  \n",
    "By evaluating and recording the RMSLE for every (store, family) pair, I produce a comprehensive CSV (`prophet_rmsle_by_pair.csv`) that enables:\n",
    "- In-depth model comparison during the evaluation phase, not just relying on aggregate metrics but analyzing per-segment performance.\n",
    "- Identification of product families or stores where Prophet under- or over-performs, which can inform further model tuning or feature engineering.\n",
    "- Transparent, reproducible results, supporting rigorous validation and fair comparison to machine learning approaches like XGBoost.\n",
    "\n",
    "This approach ensures that the baseline is not just a single number, but a rich dataset for thorough, segment-level evaluation and insight in the next stage of the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5458187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:14:48 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/1782: store_nbr=1, family=AUTOMOTIVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:14:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2/1782: store_nbr=1, family=BABY CARE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:14:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:14:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3/1782: store_nbr=1, family=BEAUTY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:14:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:14:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4/1782: store_nbr=1, family=BEVERAGES\n",
      "Processing 5/1782: store_nbr=1, family=BOOKS\n",
      "Processing 6/1782: store_nbr=1, family=BREAD/BAKERY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:14:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:14:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:14:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:14:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 7/1782: store_nbr=1, family=CELEBRATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:14:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:14:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8/1782: store_nbr=1, family=CLEANING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:14:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:14:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9/1782: store_nbr=1, family=DAIRY\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m n_valid_days = valid_pair[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m].nunique()\n\u001b[32m     25\u001b[39m future = model.make_future_dataframe(periods=n_valid_days, freq=\u001b[33m'\u001b[39m\u001b[33mD\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m forecast = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Validation actuals, aggregated\u001b[39;00m\n\u001b[32m     28\u001b[39m valid_daily = (\n\u001b[32m     29\u001b[39m     valid_pair.groupby(\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m, as_index=\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[33m'\u001b[39m\u001b[33msales\u001b[39m\u001b[33m'\u001b[39m].sum()\n\u001b[32m     30\u001b[39m     .rename(columns={\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mds\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msales\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m     31\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI_PROJECT/store-sales-time-series-forecasting/venv/lib/python3.13/site-packages/prophet/forecaster.py:1275\u001b[39m, in \u001b[36mProphet.predict\u001b[39m\u001b[34m(self, df, vectorized)\u001b[39m\n\u001b[32m   1273\u001b[39m seasonal_components = \u001b[38;5;28mself\u001b[39m.predict_seasonal_components(df)\n\u001b[32m   1274\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.uncertainty_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m     intervals = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_uncertainty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1276\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1277\u001b[39m     intervals = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI_PROJECT/store-sales-time-series-forecasting/venv/lib/python3.13/site-packages/prophet/forecaster.py:1440\u001b[39m, in \u001b[36mProphet.predict_uncertainty\u001b[39m\u001b[34m(self, df, vectorized)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_uncertainty\u001b[39m(\u001b[38;5;28mself\u001b[39m, df: pd.DataFrame, vectorized: \u001b[38;5;28mbool\u001b[39m) -> pd.DataFrame:\n\u001b[32m   1429\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Prediction intervals for yhat and trend.\u001b[39;00m\n\u001b[32m   1430\u001b[39m \n\u001b[32m   1431\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1438\u001b[39m \u001b[33;03m    Dataframe with uncertainty intervals.\u001b[39;00m\n\u001b[32m   1439\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1440\u001b[39m     sim_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample_posterior_predictive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1442\u001b[39m     lower_p = \u001b[32m100\u001b[39m * (\u001b[32m1.0\u001b[39m - \u001b[38;5;28mself\u001b[39m.interval_width) / \u001b[32m2\u001b[39m\n\u001b[32m   1443\u001b[39m     upper_p = \u001b[32m100\u001b[39m * (\u001b[32m1.0\u001b[39m + \u001b[38;5;28mself\u001b[39m.interval_width) / \u001b[32m2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI_PROJECT/store-sales-time-series-forecasting/venv/lib/python3.13/site-packages/prophet/forecaster.py:1478\u001b[39m, in \u001b[36mProphet.sample_posterior_predictive\u001b[39m\u001b[34m(self, df, vectorized)\u001b[39m\n\u001b[32m   1476\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[32m   1477\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m vectorized:\n\u001b[32m-> \u001b[39m\u001b[32m1478\u001b[39m         sims = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample_model_vectorized\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1479\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1480\u001b[39m \u001b[43m            \u001b[49m\u001b[43mseasonal_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseasonal_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1481\u001b[39m \u001b[43m            \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1482\u001b[39m \u001b[43m            \u001b[49m\u001b[43ms_a\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomponent_cols\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43madditive_terms\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[43m            \u001b[49m\u001b[43ms_m\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomponent_cols\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmultiplicative_terms\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1484\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43msamp_per_iter\u001b[49m\n\u001b[32m   1485\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1486\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1487\u001b[39m         sims = [\n\u001b[32m   1488\u001b[39m             \u001b[38;5;28mself\u001b[39m.sample_model(\n\u001b[32m   1489\u001b[39m                 df=df,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1494\u001b[39m             ) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(samp_per_iter)\n\u001b[32m   1495\u001b[39m         ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AI_PROJECT/store-sales-time-series-forecasting/venv/lib/python3.13/site-packages/prophet/forecaster.py:1556\u001b[39m, in \u001b[36mProphet.sample_model_vectorized\u001b[39m\u001b[34m(self, df, seasonal_features, iteration, s_a, s_m, n_samples)\u001b[39m\n\u001b[32m   1554\u001b[39m trends = \u001b[38;5;28mself\u001b[39m.sample_predictive_trend_vectorized(df, n_samples, iteration)  \u001b[38;5;66;03m# already on the same scale as the actual data\u001b[39;00m\n\u001b[32m   1555\u001b[39m sigma = \u001b[38;5;28mself\u001b[39m.params[\u001b[33m'\u001b[39m\u001b[33msigma_obs\u001b[39m\u001b[33m'\u001b[39m][iteration]\n\u001b[32m-> \u001b[39m\u001b[32m1556\u001b[39m noise_terms = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m * \u001b[38;5;28mself\u001b[39m.y_scale\n\u001b[32m   1558\u001b[39m simulations = []\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trend, noise \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(trends, noise_terms):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "split_date = '2016-08-16'\n",
    "results = []\n",
    "\n",
    "# Get all unique (store_nbr, family) pairs, sorted for reproducibility\n",
    "pairs = df[['store_nbr', 'family']].drop_duplicates().sort_values(['store_nbr', 'family']).reset_index(drop=True)\n",
    "\n",
    "for i, row in pairs.iterrows():\n",
    "    store, fam = row['store_nbr'], row['family']\n",
    "    print(f\"Processing {i+1}/{len(pairs)}: store_nbr={store}, family={fam}\")\n",
    "    pair_df = df[(df['store_nbr'] == store) & (df['family'] == fam)].copy()\n",
    "    train_pair = pair_df[pair_df['date'] < split_date]\n",
    "    valid_pair = pair_df[pair_df['date'] >= split_date]\n",
    "    if train_pair.empty or valid_pair.empty:\n",
    "        # You can log skipped pairs if you want: print(f\"Skipped pair {store}, {fam}\")\n",
    "        continue\n",
    "    # Aggregate daily for Prophet\n",
    "    train_prophet = (\n",
    "        train_pair.groupby('date', as_index=False)['sales'].sum()\n",
    "        .rename(columns={'date': 'ds', 'sales': 'y'})\n",
    "    )\n",
    "    # Prophet model\n",
    "    model = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=False)\n",
    "    model.fit(train_prophet)\n",
    "    n_valid_days = valid_pair['date'].nunique()\n",
    "    future = model.make_future_dataframe(periods=n_valid_days, freq='D')\n",
    "    forecast = model.predict(future)\n",
    "    # Validation actuals, aggregated\n",
    "    valid_daily = (\n",
    "        valid_pair.groupby('date', as_index=False)['sales'].sum()\n",
    "        .rename(columns={'date': 'ds', 'sales': 'y'})\n",
    "    )\n",
    "    # Merge predictions to actuals, handle NaN/negative\n",
    "    forecast_valid = forecast[['ds', 'yhat']]\n",
    "    merged = valid_daily.merge(forecast_valid, on='ds', how='left').dropna()\n",
    "    merged['y'] = merged['y'].fillna(0).clip(lower=0)\n",
    "    merged['yhat'] = merged['yhat'].fillna(0).clip(lower=0)\n",
    "    try:\n",
    "        rmsle = np.sqrt(mean_squared_log_error(merged['y'], merged['yhat']))\n",
    "    except ValueError as e:\n",
    "        rmsle = np.nan  # Handle cases where all predictions are zero or NaN\n",
    "    # Save result\n",
    "    results.append({\n",
    "        'store_nbr': store,\n",
    "        'family': fam,\n",
    "        'rmsle': rmsle,\n",
    "        'n_valid_days': n_valid_days,\n",
    "        'mean_valid_sales': merged['y'].mean(),\n",
    "        'median_valid_sales': merged['y'].median()\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.describe())\n",
    "results_df.to_csv(\"../data/processed/prophet_rmsle_by_pair.csv\", index=False)\n",
    "print(\"Average Prophet RMSLE across all (store, family) pairs: \", results_df['rmsle'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61556db",
   "metadata": {},
   "source": [
    "### Prophet Model Mean RMSLE\n",
    "\n",
    "The per-pair RMSLE scores from Prophet are saved in [`/data/processed/prophet_rmsle_by_pair.csv`](../data/processed/prophet_rmsle_by_pair.csv).\n",
    "\n",
    "Below, we report the mean RMSLE across all (store, family) pairs as a quick validation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63f9ec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Prophet RMSLE (all pairs): 0.7218\n"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(\"../data/processed/prophet_rmsle_by_pair.csv\")\n",
    "print(\"Mean Prophet RMSLE (all pairs):\", round(results['rmsle'].mean(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a509e1c4",
   "metadata": {},
   "source": [
    "## XGBoost Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e68dcf",
   "metadata": {},
   "source": [
    "### Objective and Approach\n",
    "\n",
    "The goal of this section is to train a high-performing sales forecasting model using the XGBoost algorithm. XGBoost is a gradient-boosted tree method that excels at handling structured data and capturing complex, nonlinear relationships.\n",
    "\n",
    "Our main objectives are:\n",
    "- **Leverage rich feature engineering:** Use lagged sales, rolling means, date-related variables, promotions, and outlier flags to help the model recognize patterns and seasonality in the sales data.\n",
    "- **Tune hyperparameters for best validation performance:** Systematically search for the optimal combination of XGBoost hyperparameters (such as tree depth, learning rate, number of trees, regularization, etc.) that minimize RMSLE (Root Mean Squared Logarithmic Error) on the validation set.\n",
    "- **Compare to other models:** Establish XGBoost as a strong baseline and benchmark, aiming to outperform simpler methods (like Prophet and naive forecasts) and meet or exceed competition baselines.\n",
    "\n",
    "The best-performing XGBoost model will be saved and later used for final testing and deployment as part of the interactive dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75c2ce3",
   "metadata": {},
   "source": [
    "### Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for XGBoost\n",
    "feature_cols = [\n",
    "    'store_nbr', 'family', 'onpromotion', 'transactions_x', 'is_sales_outlier', 'is_holiday',\n",
    "    'high_promo', 'sales_lag_1', 'sales_lag_7', 'sales_lag_14', 'sales_lag_28',\n",
    "    'sales_rolling_7', 'sales_rolling_14', 'sales_rolling_28', 'sales_rolling_30', 'sales_rolling_90',\n",
    "    'day', 'month', 'year', 'week', 'weekday', 'is_weekend', 'city', 'state', 'type', 'cluster',\n",
    "    'dcoilwtico'\n",
    "]\n",
    "\n",
    "# Convert categorical features to category codes\n",
    "for col in ['family', 'city', 'state', 'type']:\n",
    "    train_df[col] = train_df[col].astype('category').cat.codes\n",
    "    valid_df[col] = valid_df[col].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c315caff",
   "metadata": {},
   "source": [
    "#### Feature Selection for XGBoost\n",
    "\n",
    "For XGBoost modeling, I selected a diverse set of features designed to capture the most important drivers of sales variation across stores and product families:\n",
    "\n",
    "- **Store and Product Identifiers:**  \n",
    "  `store_nbr` and `family` allow the model to learn location- and product-specific sales patterns.\n",
    "\n",
    "- **Promotions and Transactions:**  \n",
    "  Features such as `onpromotion`, `transactions_x`, `is_sales_outlier`, `high_promo`, and `is_holiday` capture demand spikes due to promotions, sales anomalies, and holiday effects.\n",
    "\n",
    "- **Lag and Rolling Features:**  \n",
    "  Including lagged sales and rolling statistics (`sales_lag_1`, `sales_lag_7`, `sales_rolling_7`, etc.) allows the model to recognize temporal dependencies, recurring patterns, and recent momentum in sales.\n",
    "\n",
    "- **Calendar Features:**  \n",
    "  Date-based attributes (`day`, `month`, `year`, `week`, `weekday`, `is_weekend`) help model seasonal effects, day-of-week trends, and year-over-year changes.\n",
    "\n",
    "- **Geographic and Store Attributes:**  \n",
    "  Categorical variables such as `city`, `state`, `type`, and `cluster` enable the model to differentiate between locations and store types.\n",
    "\n",
    "- **External Data:**  \n",
    "  The `dcoilwtico` feature introduces macroeconomic context via oil price, which can influence consumer spending and supply chain dynamics.\n",
    "\n",
    "Categorical features are encoded as integer codes to ensure compatibility with XGBoost.  \n",
    "This comprehensive feature set aims to balance domain knowledge, temporal structure, and predictive power, providing the model with the information needed to capture complex sales drivers and improve forecast accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c612d",
   "metadata": {},
   "source": [
    "### XGBoost Hyperparameter Search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c61481",
   "metadata": {},
   "source": [
    "\n",
    "To maximize the predictive performance of the XGBoost model, I conducted an extensive grid search across a broad range of hyperparameters, including tree depth, learning rate, number of estimators, subsampling ratios, regularization terms, and more. The goal was to identify the most effective parameter combination for the sales forecasting task.\n",
    "\n",
    "Given the large parameter space, this process was computationally intensive and required several hours to complete. To ensure reproducibility and transparency, all resultsâ€”including every tested parameter combination and its validation RMSLEâ€”were saved to a CSV file, which can be found here [`/data/processed/xgb_hyperparam_results.csv`](../data/processed/xgb_hyperparam_results.csv). In this notebook, I report and visualize the top-performing configurations.\n",
    "\n",
    "**Note:**  \n",
    "While a comprehensive grid search provides a thorough evaluation of parameter options, it can be impractical for larger datasets or limited compute environments. In typical production settings, practitioners often employ more efficient methods such as `RandomizedSearchCV` or Bayesian optimization, which can deliver similar or better results with far less computational effort. Here, I opted for a full grid search to demonstrate both rigor and process, but the search itself was performed offline; only the results are included in this notebook for evaluation.\n",
    "\n",
    "This approach ensures that model tuning is both robust and reproducible, and that all findings can be verified independently from the raw search results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe22aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=4, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=6, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=8, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=10, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.3\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.1\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.05\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.01\n",
      "Testing: max_depth=12, n_estimators=300, learning_rate=0.01\n",
      "   max_depth  n_estimators  learning_rate  subsample  colsample_bytree  \\\n",
      "0         12           200           0.05        0.8               1.0   \n",
      "1         12           100           0.10        0.8               1.0   \n",
      "2         12           200           0.05        1.0               1.0   \n",
      "3         12           300           0.05        0.8               1.0   \n",
      "4         12           200           0.05        0.6               1.0   \n",
      "\n",
      "   best_iteration  validation_rmsle  \n",
      "0             200          0.500468  \n",
      "1             100          0.501062  \n",
      "2             200          0.502550  \n",
      "3             300          0.502565  \n",
      "4             200          0.502978  \n",
      "Results saved to ../data/processed/xgb_hyperparam_results.csv\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# XGBoost parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8, 10, 12],                 \n",
    "    'n_estimators': [100, 200, 300],                \n",
    "    'learning_rate': [0.3, 0.1, 0.05, 0.01],         \n",
    "    'subsample': [0.6, 0.8, 1.0],                    \n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],             \n",
    "}\n",
    "\n",
    "# Prepare feature and target\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df['sales']\n",
    "X_valid = valid_df[feature_cols]\n",
    "y_valid = valid_df['sales']\n",
    "\n",
    "results = []\n",
    "\n",
    "# Grid search loop\n",
    "for max_depth, n_estimators, learning_rate, subsample, colsample_bytree in product(\n",
    "    param_grid['max_depth'],\n",
    "    param_grid['n_estimators'],\n",
    "    param_grid['learning_rate'],\n",
    "    param_grid['subsample'],\n",
    "    param_grid['colsample_bytree']\n",
    "):\n",
    "    print(f\"Testing: max_depth={max_depth}, n_estimators={n_estimators}, learning_rate={learning_rate}\")\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        random_state=RANDOM_SEED,\n",
    "        tree_method='hist',\n",
    "        verbosity=0\n",
    "    )\n",
    "    xgb.fit(\n",
    "        X_train, y_train,\n",
    "        verbose=False\n",
    "    )\n",
    "    preds = xgb.predict(X_valid)\n",
    "    preds = np.clip(preds, 0, None)\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_valid, preds))\n",
    "    best_iteration = xgb.best_iteration if hasattr(xgb, 'best_iteration') else n_estimators\n",
    "    results.append({\n",
    "        'max_depth': max_depth,\n",
    "        'n_estimators': n_estimators,\n",
    "        'learning_rate': learning_rate,\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'best_iteration': best_iteration,\n",
    "        'validation_rmsle': rmsle\n",
    "    })\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('validation_rmsle').reset_index(drop=True)\n",
    "print(results_df.head())\n",
    "results_df.to_csv(\"../data/processed/xgb_hyperparam_results.csv\", index=False)\n",
    "print(\"Results saved to ../data/processed/xgb_hyperparam_results.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed3487",
   "metadata": {},
   "source": [
    "#### Top XGBoost Parameter Sets\n",
    "\n",
    "Below are the 10 parameter combinations that achieved the lowest validation RMSLE in the hyperparameter search.  \n",
    "These results are visualized to help guide further model selection and justify next steps in the modeling workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bbcb575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 parameter sets with lowest validation RMSLE:\n",
      "   max_depth  n_estimators  learning_rate  subsample  colsample_bytree  \\\n",
      "0         12           200           0.05        0.8               1.0   \n",
      "1         12           100           0.10        0.8               1.0   \n",
      "2         12           200           0.05        1.0               1.0   \n",
      "3         12           300           0.05        0.8               1.0   \n",
      "4         12           200           0.05        0.6               1.0   \n",
      "5         12           200           0.05        0.8               0.8   \n",
      "6         12           100           0.10        0.6               0.8   \n",
      "7         12           300           0.05        0.6               1.0   \n",
      "8         12           100           0.10        0.8               0.8   \n",
      "9         12           300           0.05        1.0               1.0   \n",
      "\n",
      "   best_iteration  validation_rmsle  \n",
      "0             200          0.500468  \n",
      "1             100          0.501062  \n",
      "2             200          0.502550  \n",
      "3             300          0.502565  \n",
      "4             200          0.502978  \n",
      "5             200          0.504331  \n",
      "6             100          0.504385  \n",
      "7             300          0.504528  \n",
      "8             100          0.504638  \n",
      "9             300          0.504672  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIjCAYAAAAQgZNYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUEJJREFUeJzt3Xd4VNX+/v17EtIEMpBAmiRI7yDSDCigoBApB5EmKMUCKooYjxUBEQFRRBBp8SvkSFPhIAgeQESKIiqIEVHpXQggSEIgPfv5wyfzY0hhBjOZ7Mz7dV1zkVl7zd6fZCfhnpW117YYhmEIAAAAMCEvdxcAAAAAXC/CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLABJ0pEjR2SxWBQfH29re/XVV2WxWBx6vcVi0auvvlqkNbVv317t27cv0n2iYBaLRU8++aS7yzANd39/cr6AvxFmARPq3r27brjhBl28eLHAPgMGDJCvr6/OnTtXjJU577ffftOrr76qI0eOuLsUm02bNslisdge3t7eCgkJUa9evfT777/n6T948GBZLBYFBgYqNTU1z/b9+/fb9jVlyhS7bUeOHNGQIUNUo0YN+fv7KywsTG3bttXYsWPt+rVv314NGzYstO7cNx8FPRITE6/jqwF3+vbbb/Xqq6/qwoUL7i4FKLHKuLsAAM4bMGCAVq1apU8//VQDBw7Ms/3y5ctauXKlOnfurODg4Os+ziuvvKIXX3zxn5R6Tb/99pvGjRun9u3b66abbrLb9sUXX7j02NcyYsQItWjRQpmZmdq1a5fmzJmjTZs2affu3QoLC7PrW6ZMGV2+fFmrVq1Snz597LYtWrRI/v7+SktLs2s/cOCAWrRooYCAAD300EO66aabdOrUKe3cuVOTJ0/WuHHjrqvu2bNnq1y5cnnaK1SocF37g/t8++23GjdunAYPHsz5AwpAmAVMqHv37ipfvrwWL16cb5hduXKlLl26pAEDBvyj45QpU0Zlyrjv14Svr6/bji1Jt99+u3r16mV7XqdOHT3++OP68MMP9fzzz9v19fPzU5s2bbRkyZI8YXbx4sXq0qWL/vvf/9q1v/POO0pJSVFCQoKqVq1qt+3MmTPXXXevXr1UqVKl6349AJgJ0wwAEwoICFDPnj21YcOGfEPP4sWLVb58eXXv3l3nz5/Xv//9bzVq1EjlypVTYGCgYmJi9PPPP1/zOPnNmU1PT9czzzyjypUr245x4sSJPK89evSonnjiCdWpU0cBAQEKDg5W79697aYTxMfHq3fv3pKkO+64w/bn8E2bNknKf07imTNn9PDDDys0NFT+/v5q0qSJ/vOf/9j1yZ3/O2XKFMXFxalGjRry8/NTixYttH379mt+3gW5/fbbJUkHDx7Md3v//v21Zs0auz8Jb9++Xfv371f//v3z9D948KCqVKmSJ8hKUkhIyHXX+U8tWrRIderUkb+/v5o1a6YtW7bYtm3cuFEWi0WffvppntctXrxYFotF27ZtK3Df8fHxslgs+uabbzRixAhVrlxZFSpU0LBhw5SRkaELFy5o4MCBqlixoipWrKjnn39ehmHY7WPKlClq3bq1goODFRAQoGbNmmnZsmV2febPny+LxaJ58+bZtU+cOFEWi0X/+9//nPqa5H4fBQQEqGXLlvr666/z7Zeenq6xY8eqZs2a8vPzU2RkpJ5//nmlp6fb9cud71rY1/rVV1/Vc889J0mqVq2a7efj6ik5K1asUMOGDeXn56cGDRpo7dq1Tn1ugNkRZgGTGjBggLKysvTJJ5/YtZ8/f17r1q3Tvffeq4CAAB06dEgrVqxQ165dNXXqVD333HP65Zdf1K5dO508edLp4z7yyCOaNm2a7r77br3xxhvy8fFRly5d8vTbvn27vv32W/Xr10/vvvuuHnvsMW3YsEHt27fX5cuXJUlt27bViBEjJEkvv/yyFixYoAULFqhevXr5Hjs1NVXt27fXggULNGDAAL311luyWq0aPHiwpk+fnqf/4sWL9dZbb2nYsGF6/fXXdeTIEfXs2VOZmZlOf96SbCGiYsWK+W7v2bOnLBaLli9fbldD3bp1dcstt+TpX7VqVR0/flxfffXVddVTkPPnz+vPP/+0ezg653Lz5s0aOXKkHnjgAb322ms6d+6cOnfurN27d0v6+w1GZGSkFi1alOe1ixYtUo0aNRQdHX3N4zz11FPav3+/xo0bp+7duysuLk6jR49Wt27dlJ2drYkTJ+q2227TW2+9pQULFti9dvr06WratKlee+01TZw4UWXKlFHv3r31+eef2/oMGTJEXbt2VWxsrI4fPy5J+uWXXzRu3Dg9/PDDuueeexz6ekjSBx98oGHDhiksLExvvvmm2rRpo+7du9v2mysnJ0fdu3fXlClT1K1bN82YMUM9evTQO++8o759++bZ77W+1j179tT9998v6e9R/Nyfj8qVK9v28c033+iJJ55Qv3799OabbyotLU333XdfiZ8rDxQpA4ApZWVlGeHh4UZ0dLRd+5w5cwxJxrp16wzDMIy0tDQjOzvbrs/hw4cNPz8/47XXXrNrk2TMnz/f1jZ27Fjjyl8TCQkJhiTjiSeesNtf//79DUnG2LFjbW2XL1/OU/O2bdsMScaHH35oa1u6dKkhydi4cWOe/u3atTPatWtnez5t2jRDkrFw4UJbW0ZGhhEdHW2UK1fOSE5OtvtcgoODjfPnz9v6rly50pBkrFq1Ks+xrrRx40ZDkjFv3jzj7NmzxsmTJ421a9caNWvWNCwWi/HDDz/Y9R80aJBRtmxZwzAMo1evXkaHDh0MwzCM7OxsIywszBg3bpytprfeesv2ut27dxsBAQGGJOPmm282nn76aWPFihXGpUuX8v1aNGjQoNC6c89Xfo86deoU+lrDMGx9d+zYYWs7evSo4e/vb9x77722tpdeesnw8/MzLly4YGs7c+aMUaZMGbvvgfzMnz/fkGR06tTJyMnJsbVHR0cbFovFeOyxx2xtWVlZRpUqVey+Bwwj7/dWRkaG0bBhQ+POO++0az916pQRFBRk3HXXXUZ6errRtGlTIyoqykhKSrrm1+LKfYeEhBg333yzkZ6ebmuPi4szJNnVtmDBAsPLy8v4+uuv7faR+zO5detWW5ujX+u33nrLkGQcPnw4T22SDF9fX+PAgQO2tp9//tmQZMyYMcPhzxEwO0ZmAZPy9vZWv379tG3bNrs/Oy5evFihoaHq0KGDpL/ncnp5/f2jnp2drXPnzqlcuXKqU6eOdu7c6dQxc/80mzuammvkyJF5+gYEBNg+zszM1Llz51SzZk1VqFDB6eNeefywsDDbaJUk+fj4aMSIEUpJSdHmzZvt+vft29duFDV3msChQ4ccOt5DDz2kypUrKyIiQp07d1ZSUpIWLFigFi1aFPia/v37a9OmTUpMTNRXX32lxMTEfKcYSFKDBg2UkJCgBx54QEeOHNH06dPVo0cPhYaG6v3333eoxvz897//1fr16+0e8+fPd+i10dHRatasme15VFSU/vWvf2ndunXKzs6WJA0cOFDp6el2f9r/+OOPlZWVpQceeMCh4zz88MN2U1hatWolwzD08MMP29q8vb3VvHnzPOfryu+tv/76S0lJSbr99tvzfF+FhYVp5syZWr9+vW6//XYlJCRo3rx5CgwMdKhGSdqxY4fOnDmjxx57zG4O9+DBg2W1Wu36Ll26VPXq1VPdunXtRsXvvPNOSX9P0biSI1/ra+nYsaNq1Khhe964cWMFBgY6/D0OlAaEWcDEci/wWrx4sSTpxIkT+vrrr9WvXz95e3tL+vtPn++8845q1aolPz8/VapUSZUrV9auXbuUlJTk1PGOHj0qLy8vu/88pb8vjLpaamqqxowZo8jISLvjXrhwwenjXnn8WrVq2cJ5rtxpCUePHrVrj4qKsnueG2z/+usvh443ZswYrV+/3rZqRFJSUp5jX+2ee+5R+fLl9fHHH2vRokVq0aKFatasWWD/2rVra8GCBfrzzz+1a9cu25/Nhw4dqi+//NKhOq/Wtm1bdezY0e7hyJ/+JalWrVr51nj58mWdPXtWklS3bl21aNHCbqrBokWLdOuttxb6uV7p6nOTGwwjIyPztF99vlavXq1bb71V/v7+CgoKUuXKlTV79ux8v6/69eunLl266IcfftCjjz5qe5PnqNzvqau/Lj4+Pqpevbpd2/79+/Xrr7+qcuXKdo/atWtLyntRnyNf62u5+uso/f197uj3OFAasJoBYGLNmjVT3bp1tWTJEr388stasmSJDMOwW8Vg4sSJGj16tB566CGNHz9eQUFB8vLy0siRI5WTk+Oy2p566inNnz9fI0eOVHR0tKxWqywWi/r16+fS414pN9BfzbjqgqKCNGrUSB07dpQk9ejRQ5cvX9ajjz6q2267LU/oyuXn56eePXvqP//5jw4dOuTwjSS8vb3VqFEjNWrUSNHR0brjjju0aNEi2/FLmoEDB+rpp5/WiRMnlJ6eru+++07vvfeew68v6Nzk137l+fr666/VvXt3tW3bVrNmzVJ4eLh8fHw0f/5825u6K507d047duyQ9PcycDk5Odd8Q3K9cnJy1KhRI02dOjXf7QV9z/wT//R7HCgNCLOAyQ0YMECjR4/Wrl27tHjxYtWqVcvuz+DLli3THXfcoQ8++MDudRcuXHB6+aaqVasqJydHBw8etBuN3bt3b56+y5Yt06BBg/T222/b2tLS0vJciOToHcZyj79r1648gWTPnj227a70xhtv6NNPP9WECRM0Z86cAvv1799f8+bNk5eXl/r16+f0cZo3by5JOnXq1HXXer3279+fp23fvn264YYb7C486tevn2JjY7VkyRKlpqbKx8cn34ucitp///tf+fv7a926dfLz87O1FzSNYvjw4bp48aImTZqkl156SdOmTVNsbKzDx8v9ntq/f79tuoD099SZw4cPq0mTJra2GjVq6Oeff1aHDh0c+r525GvtzM8H4KmYZgCYXO4o7JgxY5SQkJBnbVlvb+88ozRLly7VH3/84fSxYmJiJEnvvvuuXfu0adPy9M3vuDNmzMgzF7Bs2bKS5NDV9vfcc48SExP18ccf29qysrI0Y8YMlStXTu3atXPk07huNWrU0H333af4+PhC76Z1xx13aPz48Xrvvffy3FzhSl9//XW+Kyvkzk3Ob/qGq23bts1u7unx48e1cuVK3X333XajgJUqVVJMTIwWLlyoRYsWqXPnzsWytq23t7csFovd99GRI0e0YsWKPH2XLVumjz/+WG+88YZefPFF9evXT6+88or27dvn8PGaN2+uypUra86cOcrIyLC1x8fH5/me7dOnj/7444985zunpqbq0qVLdm2OfK2d+fkAPBUjs4DJVatWTa1bt9bKlSslKU+Y7dq1q1577TUNGTJErVu31i+//KJFixblme/niJtvvln333+/Zs2apaSkJLVu3VobNmzQgQMH8vTt2rWrFixYIKvVqvr162vbtm368ssv89yR7Oabb5a3t7cmT56spKQk+fn56c4778x3ndWhQ4dq7ty5Gjx4sH788UfddNNNWrZsmbZu3app06apfPnyTn9Oznruuef0ySefaNq0aXrjjTfy7ePl5aVXXnnlmvuaPHmyfvzxR/Xs2VONGzeWJO3cuVMffvihgoKC8lxYd/bsWb3++ut59lOtWjW7875s2bJ87wB21113KTQ0tNCaGjZsqE6dOmnEiBHy8/PTrFmzJCnfu5ENHDjQdlOJ8ePHF/7JFpEuXbpo6tSp6ty5s/r3768zZ85o5syZqlmzpnbt2mXrd+bMGT3++OO644479OSTT0qS3nvvPW3cuFGDBw/WN99849B0Ax8fH73++usaNmyY7rzzTvXt21eHDx/W/Pnz8/wMPfjgg/rkk0/02GOPaePGjWrTpo2ys7O1Z88effLJJ1q3bp1t1F1y7Gude4HYqFGj1K9fP/n4+Khbt262kAtALM0FlAYzZ840JBktW7bMsy0tLc149tlnjfDwcCMgIMBo06aNsW3btjzLXjmyNJdhGEZqaqoxYsQIIzg42ChbtqzRrVs34/jx43mW5vrrr7+MIUOGGJUqVTLKlStndOrUydizZ49RtWpVY9CgQXb7fP/9943q1asb3t7edst0XV2jYRjG6dOnbfv19fU1GjVqZFfzlZ/Llctg5bq6zvzkLs21dOnSfLe3b9/eCAwMtC1NdeXSXAXJr6atW7caw4cPNxo2bGhYrVbDx8fHiIqKMgYPHmwcPHjQ7vXt2rUrcNmt3KXAClua68qva0EkGcOHDzcWLlxo1KpVy/Dz8zOaNm1a4OvS09ONihUrGlar1UhNTS1037lyl+bavn27XXtu7WfPnrVrz+9r+8EHH9jqq1u3rjF//vw836s9e/Y0ypcvbxw5csTutbnLs02ePNmhenPNmjXLqFatmuHn52c0b97c2LJlS77fnxkZGcbkyZONBg0aGH5+fkbFihWNZs2aGePGjbNbEsyZr/X48eONG2+80fDy8rJbpit3H1fL72cMKM0shsEscQCA87KyshQREaFu3brlmZONwlksFg0fPtypi+YA5I85swCA67JixQqdPXtWAwcOdHcpADwYc2YBAE75/vvvtWvXLo0fP15NmzZ1+YV3rnL+/Hm7i7qu5u3tbbeCA4CSiTALAHDK7NmztXDhQt18882Kj493dznXrWfPnnnuGnelqlWr2t1dD0DJxJxZAIBH+vHHHwu9U1ZAQIDatGlTjBUBuB6EWQAAAJgWF4ABAADAtDxuzmxOTo5Onjyp8uXLc5tAAACAEsgwDF28eFERERHXvMGJx4XZkydPKjIy0t1lAAAA4BqOHz+uKlWqFNrH48Js7u0ujx8/rsDAQDdXAwAAgKslJycrMjLSoduUe1yYzZ1aEBgYSJgFAAAowRyZEsoFYAAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwqwHOHnypLp27aoOHTqoa9euOnnypLtLAgAAKBJl3F0AXOuuu+5SZmam7XlKSor69+8vHx8frV+/3o2VwVVSU1M1d+5cnThxQlWqVNGwYcMUEBDg7rLgIpxvz8L59izZ2dnatWuXzp8/r6CgIDVu3Fje3t7uLqvEsRiGYbi7iOKUnJwsq9WqpKQkBQYGurscl7oyyAYFBWnYsGGaO3euzp8/L0kE2lJo1KhR2rp1a572Nm3aaMKECW6oCK7E+fYsnG/PsmXLFs2YMUNnz561tVWuXFlPPfWU2rZt68bKioczeY1pBqXUyZMnbUF2+fLlWr58uTp16mT7WJIyMzOZclCKFPQfnSRt3bpVo0aNKuaK4Eqcb8/C+fYsW7Zs0ZgxY+yCrCSdPXtWY8aM0ZYtW9xUWclEmC2lhg4dKunvEdmgoCC7bVe25faDuaWmptr9R1e/fn29/fbbql+/vq1t69atSk1NdUd5KGKcb8/C+fYs2dnZGjt2rO15WFiYxo4dq7CwMFvb2LFjlZ2d7Y7ySiTmzJZSub/Uhg0blu/2hx56SFOmTOGXXykxffp028erV69WuXLlJEnNmjVTSkqKunbtauv34osvuqVGFB3Ot2fhfHuWTZs2KXcG6IoVK1ShQgVJ0h133KELFy6oR48eMgxDmzZtUocOHdxYacnByGwplXtBwNy5c/PdPm/ePLt+MLdNmzZJkmrWrGn7jy5XuXLlVL16dbt+MDfOt2fhfHuWqVOnSpJCQkJsQTZXhQoVFBISYtcPhNlSKy4uTpJ0/vx52wVfua5sy+0Hc8vKypIkRUVF5bs9tz23H8yN8+1ZON+eJS0tTZLUrVu3fLfHxMTY9QNhttSKiIiQj4+PJKlnz57q2bOnVq9ebftY+ns1g4iICHeWiSISHh4uSfrqq6+UkZFhty0jI8M2YpPbD+bG+fYsnG/PUr58eUnSwoULlZOTY7ctJydHH330kV0/sDSXu8txuavXmc3Fslyly/nz521vUsqUKaPevXvrnnvu0f/+9z8tXbrUNmKzfPnyPBcEwnw4356F8+1ZEhMT1a9fP0lSixYtNHjwYFWrVk2HDx9WfHy8tm/fLkn66KOP7C4KK22cyWuEWQ9w8uRJDR06VKmpqQoICFBcXBwjsqVQz54980wpuVJQUJBtWTaYH+fbs3C+PUvnzp0LnUbg7++vtWvXFmNFxY8wWwhPDLPwHAX9h8d/dKUT59uzcL49S0GB1hOCrESYLRRhFqXd+fPnFRsbq3Pnzik4OFhTp07lT4+lGOfbs3C+PUtiYqIef/xxpaSkqFy5cpo9e3apnlpwJcJsIQizAAAAJRu3swUAAIBHIMwCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtNwaZidNmqQWLVqofPnyCgkJUY8ePbR3795CXxMfHy+LxWL38Pf3L6aKAQAAUJK4Ncxu3rxZw4cP13fffaf169crMzNTd999ty5dulTo6wIDA3Xq1Cnb4+jRo8VUMQAAAEqSMu48+Nq1a+2ex8fHKyQkRD/++KPatm1b4OssFovCwsJcXR4AAABKuBI1ZzYpKUmSFBQUVGi/lJQUVa1aVZGRkfrXv/6lX3/9tcC+6enpSk5OtnsAAACgdCgxYTYnJ0cjR45UmzZt1LBhwwL71alTR/PmzdPKlSu1cOFC5eTkqHXr1jpx4kS+/SdNmiSr1Wp7REZGuupTAAAAQDGzGIZhuLsISXr88ce1Zs0affPNN6pSpYrDr8vMzFS9evV0//33a/z48Xm2p6enKz093fY8OTlZkZGRSkpKUmBgYJHUDgAAgKKTnJwsq9XqUF5z65zZXE8++aRWr16tLVu2OBVkJcnHx0dNmzbVgQMH8t3u5+cnPz+/oigTAAAAJYxbpxkYhqEnn3xSn376qb766itVq1bN6X1kZ2frl19+UXh4uAsqBAAAQEnm1pHZ4cOHa/HixVq5cqXKly+vxMRESZLValVAQIAkaeDAgbrxxhs1adIkSdJrr72mW2+9VTVr1tSFCxf01ltv6ejRo3rkkUfc9nkAAADAPdwaZmfPni1Jat++vV37/PnzNXjwYEnSsWPH5OX1/waQ//rrLz366KNKTExUxYoV1axZM3377beqX79+cZUNAACAEqLEXABWXJyZUAwAAIDi50xeKzFLcwEAAADOIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMK0y7i4Arpeamqq5c+fqxIkTqlKlioYNG6aAgAB3lwUAAPCPWQzDMNxdRHFKTk6W1WpVUlKSAgMD3V2Oy40aNUpbt27N096mTRtNmDDBDRUBAAAUzpm8xjSDUqygICtJW7du1ahRo4q5IgAAgKJFmC2lUlNTCwyyubZu3arU1NRiqggAAKDoEWZLqZkzZ9o+9vLyUv/+/bVw4UL1799fXl5e+fYDAAAwGy4AK6W+++4728dr166Vr6+vJGno0KEaPHiw7r777jz9UDpwwR8AwJMQZkuplJQUSVKNGjVsQTaXr6+vqlevrkOHDtn6oXS4ep70jh07tGLFCi74K8V48wLA0xFmS6mAgAClpaXp0KFDysjIsAu0GRkZOnz4sK0fSofcIOvj46PevXvrnnvu0f/+9z8tXbrUdsEfgbZ04c2L5+HNi2fhfDuGpblKqbffflurVq2SJPn4+KhXr162cLNs2TJlZmZKkrp166Znn33WnaWiCKSmpiomJkY+Pj5atmyZ5s+fb/vlN2TIEPXq1UuZmZlas2YNvwhLidwgW6ZMGVWrVk2+vr62N6pZWVkE2lKIpRY9i6efb2fyGmG2lMoNN9dCuCkdpk2bphUrVujGG2/UH3/8kWd7RESETp48qR49emjkyJHFXyCKVO7Pt8ViUX6/wnPb+fkuPa5883LDDTcoKytLZcqU0eXLl3nzUgpxvllnFvp7+kCbNm0K7dOmTRv+oyslTpw4IUn5BllJOnnypF0/mNvcuXMlKd8ge2V7bj+Y25VLLWZlZSk5OVmXL19WcnKysrKyJLHUYmnC+XYeYbYUmzBhQoGB1hPe1XmSsLAw28eFLcV2ZT+Y17Fjx2wfF3a+r+wH87r6TUn9+vX19ttvq379+oX2gzlxvp3n1gvAJk2apOXLl2vPnj0KCAhQ69atNXnyZNWpU6fQ1y1dulSjR4/WkSNHVKtWLU2ePFn33HNPMVVtLhMmTGACuQfIzs62ffzZZ5+pXLlykv5eiq1///7q2rVrnn4wrz///NP2cWFL713ZD+aVe8GuJK1evdr2892sWTOlpKTYfr6v7Afz4nw7z60js5s3b9bw4cP13Xffaf369crMzNTdd9+tS5cuFfiab7/9Vvfff78efvhh/fTTT+rRo4d69Oih3bt3F2Pl5hIQEKCRI0dqypQpGjlyJEG2FNqxY4ft43vvvVdz587V8ePHNXfuXN1777359oN55S6pZ7FY8t2e287Se6XDwYMHJUlBQUG2YJOrXLlyCgoKsusHc+N8O8+tI7Nr1661ex4fH6+QkBD9+OOPatu2bb6vmT59ujp37qznnntOkjR+/HitX79e7733nubMmZOnf3p6utLT023Pk5OTi/AzAEqG3DmSoaGhOn36tJYsWaIlS5bYtoeEhOjMmTMFzrGEueROJTAMQ126dMmzWknueb5yygHMKycnR5KUlJSU71KLSUlJdv1gbpxv55Wo33S5Jyj3XUd+tm3bpo4dO9q1derUSdu2bcu3/6RJk2S1Wm2PyMjIoisYKCGio6MlSWfPntXKlSvVo0cPNW/eXD169NDKlSttf27O7Qdzu/I8ZmZmasmSJXrwwQe1ZMkS27J7V/eDeYWEhEj6e5pQly5d7P7y0qVLF9v0odx+MDfOt/NKzNJcOTk56t69uy5cuKBvvvmmwH6+vr76z3/+o/vvv9/WNmvWLI0bN06nT5/O0z+/kdnIyMhSvzQXPMuVS7EVtq4wSzWVDleeby8vL1WvXl3+/v62G6XkjthwvkuH8+fPq2fPntfst3z58kIHg2AOnO+/ObM0V4m5A9jw4cO1e/fuQoPs9fDz85Ofn1+R7hMoaXKXYtu6dattpO7KaQYSS7GVJlee75ycHB04cCBPH8536REUFKSgoCCdP39eklShQgVVrlxZZ8+e1YULF+z6wPw4384rEdMMnnzySa1evVobN25UlSpVCu0bFhaWZwT29OnTLDkEj8dSbJ6F8+1ZrhyFu3Dhgvbv328XbJYvX+7G6lDUON/Oces0A8Mw9NRTT+nTTz/Vpk2bVKtWrWu+pm/fvrp8+bLtVq2S1Lp1azVu3DjfC8Cu5il3AIPnYik2z8L59iznz59XbGyszp07p+DgYE2dOpURulLMk8+3aW5n+8QTT2jx4sVauXKl3dqyVqvV9st44MCBuvHGGzVp0iRJfy/N1a5dO73xxhvq0qWLPvroI02cOFE7d+5Uw4YNr3lMwiwAAEDJZprb2c6ePVtJSUlq3769wsPDbY+PP/7Y1ufYsWM6deqU7Xnr1q21ePFixcXFqUmTJlq2bJlWrFjhUJAFAABA6VJiVjMoLozMAgAAlGymGZkFAAAA/gnCLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTcjjMnjlzptDtWVlZ+uGHH/5xQQAAAICjHA6z4eHhdoG2UaNGOn78uO35uXPnFB0dXbTVAQAAAIVwOMwahmH3/MiRI8rMzCy0DwAAAOBKRTpn1mKxFOXuAAAAgEJxARgAAABMq4yjHS0Wiy5evCh/f38ZhiGLxaKUlBQlJydLku1fAAAAoLg4HGYNw1Dt2rXtnjdt2tTuOdMMAAAAUJwcDrMbN250ZR0AAACA0xwOs+3atSt0++XLl5WQkPBP6wEAAAAcVmQXgO3fv1+33357Ue0OAAAAuCZWMwAAAIBpEWYBAABgWoRZAAAAmJbDF4B99tlnhW4/fPjwPy4GAAAAcIbDYbZHjx7X7MM6swAAAChODofZnJwcV9YBAAAAOI05swAAADAth8Psvn379MMPP9i1bdiwQXfccYdatmypiRMnFnlxAAAAQGEcDrMvvPCCVq9ebXt++PBhdevWTb6+voqOjtakSZM0bdo0V9QIAAAA5MvhObM7duzQ888/b3u+aNEi1a5dW+vWrZMkNW7cWDNmzNDIkSOLvEgAAAAgPw6PzP7555+qUqWK7fnGjRvVrVs32/P27dvryJEjRVocAAAAUBiHw2xQUJBOnTol6e+VDXbs2KFbb73Vtj0jI0OGYRR9hQAAAEABHA6z7du31/jx43X8+HFNmzZNOTk5at++vW37b7/9pptuuskFJQIAAAD5c3jO7IQJE3TXXXepatWq8vb21rvvvquyZcvati9YsEB33nmnS4oEAAAA8mMxnJgbkJWVpV9//VWVK1dWRESE3baff/5ZVapUUXBwcJEXWZSSk5NltVqVlJSkwMBAd5cDAACAqziT1xwemZWkMmXKqEmTJvluK6gdAAAAcBWHw+xrr73mUL8xY8ZcdzEAAACAMxyeZuDl5aWIiAiFhIQUuGqBxWLRzp07i7TAosY0AwAAgJLNJdMMYmJi9NVXX6l58+Z66KGH1LVrV3l5ObwYAgAAAFDkHE6jn3/+uQ4ePKhWrVrpueee04033qgXXnhBe/fudWV9AAAAQIGcGlqNiIjQSy+9pL179+rjjz/WmTNn1KJFC7Vp00apqamuqhEAAADIl1OrGVypRYsWOnLkiH777Tf99NNPyszMVEBAQFHWBgAAABTK6Umv27Zt06OPPqqwsDDNmDFDgwYN0smTJ7mYCgAAAMXO4ZHZN998U/Hx8frzzz81YMAAff3112rcuLErawMAAAAK5dTSXFFRUeratat8fX0L7Dd16tQiK84VWJoLAACgZHPJ0lxt27aVxWLRr7/+WmAfi8XieJUAAADAP+RwmN20aZMLywAAAACcV6R3PdixY0dR7g4AAAAolNNhNiUlJc+asgkJCerWrZtatWpVZIUBAAAA1+JwmD1+/Liio6NltVpltVoVGxury5cva+DAgWrVqpXKli2rb7/91pW1AgAAAHYcnjP73HPPKS0tTdOnT9fy5cs1ffp0ff3112rVqpUOHjyoKlWquLJOAAAAIA+Hw+yWLVu0fPly3XrrrerTp4/CwsI0YMAAjRw50oXlAQAAAAVzeJrB6dOnVa1aNUlSSEiIbrjhBsXExLisMAAAAOBanLoAzMvLy+7jwm6eAAAAALiaw9MMDMNQ7dq1bTdGSElJUdOmTe0CriSdP3++aCsEAAAACuBwmJ0/f74r6wAAAACc5nCYHTRokCvrAAAAAJxWpHcAAwAAAIoTYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJiWw6sZ5MrOzlZ8fLw2bNigM2fOKCcnx277V199VWTFAQAAAIVxOsw+/fTTio+PV5cuXdSwYUPbTRQAAACA4uZ0mP3oo4/0ySef6J577nFFPQAAAIDDnJ4z6+vrq5o1a7qiFgAAAMApTofZZ599VtOnT5dhGK6oBwAAAHCY09MMvvnmG23cuFFr1qxRgwYN5OPjY7d9+fLlRVYcAAAAUBinw2yFChV07733uqIWAAAAwClOh9n58+e7og4AAADAaU6H2Vxnz57V3r17JUl16tRR5cqVi6woAAAAwBFOXwB26dIlPfTQQwoPD1fbtm3Vtm1bRURE6OGHH9bly5ddUSMAAACQL6fDbGxsrDZv3qxVq1bpwoULunDhglauXKnNmzfr2WefdUWNAAAAQL4shpNrbFWqVEnLli1T+/bt7do3btyoPn366OzZs0VZX5FLTk6W1WpVUlKSAgMD3V0OAAAAruJMXnN6zuzly5cVGhqapz0kJIRpBtcpLS1Nx44dc3cZRSYqKkr+/v7uLgMAAHgAp8NsdHS0xo4dqw8//NAWWFJTUzVu3DhFR0cXeYGe4NixYxo6dKi7yygycXFxql27trvLAAAAHsDpaQa7d+9Wp06dlJ6eriZNmkiSfv75Z/n7+2vdunVq0KCBSwotKiVxmkFxjMwePXpUEyZM0KhRo1S1alWXHouRWQAA8E+4dJpBw4YNtX//fi1atEh79uyRJN1///0aMGCAAgICrq9iD+fv719sI5lVq1Zl1BQAAJQa17XO7A033KBHH320qGsBAAAAnOJQmP3ss88UExMjHx8fffbZZ4X27d69e5EUBgAAAFyLQ2G2R48eSkxMVEhIiHr06FFgP4vFouzs7KKqDQAAACiUQzdNyMnJUUhIiO3jgh7OBtktW7aoW7duioiIkMVi0YoVKwrtv2nTJlksljyPxMREp44LAACA0sHpO4B9+OGHSk9Pz9OekZGhDz/80Kl9Xbp0SU2aNNHMmTOdet3evXt16tQp2yM3aAMAAMCzOH0B2JAhQ9S5c+c8AfLixYsaMmSIBg4c6PC+YmJiFBMT42wJCgkJUYUKFRzqm56ebhe+k5OTnT4eYCapqamaO3euTpw4oSpVqmjYsGGsNAIAKLWcHpk1DEMWiyVP+4kTJ2S1WoukqGu5+eabFR4errvuuktbt24ttO+kSZNktVptj8jIyGKpEXCHUaNGKSYmRitWrNCOHTu0YsUKxcTEaNSoUe4uDQAAl3B4ZLZp06a2OaodOnRQmTL/76XZ2dk6fPiwOnfu7JIic4WHh2vOnDlq3ry50tPT9X//939q3769vv/+e91yyy35vuall15SbGys7XlycjKBFqXSqFGjtHXrVvn4+Kh3796655579L///U9Lly7V1q1bNWrUKE2YMMHdZaKIMRIPwNM5HGZzVzFISEhQp06dVK5cOds2X19f3XTTTbrvvvuKvMAr1alTR3Xq1LE9b926tQ4ePKh33nlHCxYsyPc1fn5+8vPzc2ldgLulpqbaguznn38uX19fSdLQoUM1ePBgdenSRVu3blVqaipBpxTJfQOTK3c0vk2bNrxxKaV48wLk5XCYHTt2rCTppptuUt++fUvM7Upbtmypb775xt1lAG41d+5cSVLv3r2VnZ2tadOm2f1n16tXLy1ZskRz587VyJEj3VssigQj8Z6HNy+ehzcvjnH6ArBBgwa5oo7rlpCQoPDwcHeXAbjViRMnJEl79uyxu6gy9z+7pk2b2vWDuV05Er9gwQK9+OKLWrVqlYKDg7VgwQI9+OCDjMSXMrlBtkyZMqpWrZp8fX2VkZGhw4cP8+allOLNi+OcvgAsOztbU6ZMUcuWLRUWFqagoCC7hzNSUlKUkJCghIQESdLhw4eVkJCgY8eOSfp7vuuVqyNMmzZNK1eu1IEDB7R7926NHDlSX331lYYPH+7spwGUKlWqVJEk7dy5M9/tP/30k10/mFvuSLyXl5f69eunI0eO6OLFizpy5Ij69esnLy8vu34wt9w3LxaLRVlZWdq/f79+/fVX7d+/X1lZWbJYLLY3Lygdrg6yV8p984L/x+kwO27cOE2dOlV9+/ZVUlKSYmNj1bNnT3l5eenVV191al87duxQ06ZNbaNGsbGxatq0qcaMGSNJOnXqlC3YSn+vZfvss8+qUaNGateunX7++Wd9+eWX6tChg7OfBlCqXL0kXv/+/bVw4UL179+/0H4wp9wR9txlB+vXr6+3335b9evXt2tnJL50yH1TYhhGvttz23nzUjrkvnkpDG9e7Dk9zWDRokV6//331aVLF7366qu6//77VaNGDTVu3FjfffedRowY4fC+2rdvX+APpyTFx8fbPX/++ef1/PPPO1syUOrNmzfP9rGPj48Mw7A9fHx8lJmZaev373//211loohUqlTJ9vHq1attF+Q2a9ZMKSkp6tq1a55+MK8rB3VyR+Nz50h/9NFHysnJydMP5jVr1iy753fffbf69OmjTz75RF988YVdv2effba4yyuRnA6ziYmJatSokSSpXLlySkpKkiR17dpVo0ePLtrqADjk+++/lySFhobq9OnTWrJkiZYsWWLbHhISojNnztj6wdx+/fVX28e5K1fk9/zKfjCvP//80/bx2rVr86xWcvfdd+fpB/O6crrY2rVrbRfcv/zyy4qNjbUtg1rQtDJP5PQ0gypVqujUqVOSpBo1atjeJWzfvp0lsAA3yf0LR8uWLbVmzRr16NFDzZs3V48ePbRmzRq1aNHCrh/M7cKFC7aPu3Tporlz5+r48eOaO3euunTpkm8/mFdKSook5XvDoivbc/vB3M6dOyfp77x19cpR/v7+uvHGG+364TpGZu+9915t2LBBrVq10lNPPaUHHnhAH3zwgY4dO6ZnnnnGFTUCuIbo6GitWrVKn3/+uZ566im75bcyMjK0Zs0aWz+YX3BwsC5evKhy5copJSUlz0h8bntwcLAbq0RRyb2gzzAMdenSRb169bJNM1i2bJntTWpuP5ibr6+v0tLSdPLkSWVkZNj9tSUjI8M2oHj1X2U8mdNh9o033rB93LdvX0VFRWnbtm2qVauWunXrVqTFAXDME088oVWrViknJyff/+xy59Q98cQTbq4URWHq1Knq2bOnUlJStHTpUi1atMi2DuWAAQPUu3dvWz+YX+6bVUnKzMzM8+blyn4wvwYNGmjbtm3X/H3eoEEDN1daclgMD/u7Y3JysqxWq5KSkhQYGOjucorNvn37NHToUMXFxal27druLgcuUNhSLpJYm7CU6dmzp86fPy9JqlevnoYMGaL58+fr999/lyQFBQVp+fLl7iwRRSQ1NdW2frSXl5eqV68uf39/paWl6dChQ7Zws2bNGtYVLgWuvIizMFde/FkaOZPXHBqZ/eyzzxw+ePfu3R3uC6DoTJgwocBAS5AtfZYvX24LtL///rvdSi8E2dIlICBAbdq00datW5WTk6MDBw7k6dOmTRuCbClRrlw51a1bV3v27CmwT926dUt1kHWWQyOzV8/DsVgseS4kyZ2Anp2dXYTlFT1GZhmZLe24/aFnOX/+vGJjY3Xu3DkFBwdr6tSpTt/ABubAm1XP8thjj+UbaOvWras5c+a4oaLiVeQjs7l/wpCkL7/8Ui+88IImTpxom5+zbds2vfLKK5o4ceI/KBtAUQgICLC7AAylW1BQUJ41uVE6TZgwgTerHmTOnDlKSUnRpEmTdPLkSUVEROill15iRDYfTl8ANnLkSM2ZM0e33Xabra1Tp0664YYbNHToUNt8LQAAULR4s+pZypUrx6i7A5xex+PgwYOqUKFCnnar1aojR44UQUkAAACAY5wOsy1atFBsbKxOnz5tazt9+rSee+45tWzZskiLAwAAAArjdJidN2+eTp06paioKNWsWVM1a9ZUVFSU/vjjD33wwQeuqBEAAADIl9NzZmvWrKldu3Zp/fr1tqvs6tWrp44dOxZ4qz0AAADAFZwOs9Lfy3Ddfffduvvuu4u6HgAAAMBhDoXZd999V0OHDpW/v7/efffdQvuOGDGiSAoDAAAArsWhMPvOO+9owIAB8vf31zvvvFNgP4vFQpgFAABAsXEozB4+fDjfjwEAAAB3cno1AwAAAKCkcGhkNjY21uEdTp069bqLAQAAAJzhUJj96aefHNoZS3MBAACgODkUZjdu3OjqOgAAAACnMWcWAAAApnVdN03YsWOHPvnkEx07dkwZGRl225YvX14khQEAAADX4vTI7EcffaTWrVvr999/16effqrMzEz9+uuv+uqrr2S1Wl1RIwAAAJAvp8PsxIkT9c4772jVqlXy9fXV9OnTtWfPHvXp00dRUVGuqBEAAADIl9Nh9uDBg+rSpYskydfXV5cuXZLFYtEzzzyjuLi4Ii8QAAAAKIjTYbZixYq6ePGiJOnGG2/U7t27JUkXLlzQ5cuXi7Y6AAAAoBBOXwDWtm1brV+/Xo0aNVLv3r319NNP66uvvtL69evVoUMHV9QIAAAA5MvhMLt79241bNhQ7733ntLS0iRJo0aNko+Pj7799lvdd999euWVV1xWKAAAAHA1h8Ns48aN1aJFCz3yyCPq16+fJMnLy0svvviiy4oDAAAACuPwnNnNmzerQYMGevbZZxUeHq5Bgwbp66+/dmVtAAAAQKEcDrO333675s2bp1OnTmnGjBk6cuSI2rVrp9q1a2vy5MlKTEx0ZZ0AAABAHk6vZlC2bFkNGTJEmzdv1r59+9S7d2/NnDlTUVFR6t69uytqBAAAAPLldJi9Us2aNfXyyy/rlVdeUfny5fX5558XVV0AAADANTm9NFeuLVu2aN68efrvf/8rLy8v9enTRw8//HBR1gYAAAAUyqkwe/LkScXHxys+Pl4HDhxQ69at9e6776pPnz4qW7asq2oEAAAA8uVwmI2JidGXX36pSpUqaeDAgXrooYdUp04dV9YGAAAAFMrhMOvj46Nly5apa9eu8vb2dmVNAAAAgEMcDrOfffaZK+sAAAAAnPaPVjMAAAAA3IkwCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMq4+4CzOL06dNKSkpydxnX7ejRo3b/mpnValVoaKi7ywAAACWAxTAMw91FFKfk5GRZrVYlJSUpMDDQodecPn1aDzw4UJkZ6S6uDo7w8fXTwgUfEmgBACilnMlrjMw6ICkpSZkZ6Uqt3k45/lZ3l+PRvNKSpEOblZSURJgFAACEWWfk+FuVU7aSu8sAAADA/48LwAAAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBabg2zW7ZsUbdu3RQRESGLxaIVK1Zc8zWbNm3SLbfcIj8/P9WsWVPx8fEurxMAAAAlk1vD7KVLl9SkSRPNnDnTof6HDx9Wly5ddMcddyghIUEjR47UI488onXr1rm4UgAAAJREZdx58JiYGMXExDjcf86cOapWrZrefvttSVK9evX0zTff6J133lGnTp1cVSYAAABKKFPNmd22bZs6duxo19apUydt27atwNekp6crOTnZ7gEAAIDSwVRhNjExUaGhoXZtoaGhSk5OVmpqar6vmTRpkqxWq+0RGRlZHKUCAACgGJgqzF6Pl156SUlJSbbH8ePH3V0SAAAAiohb58w6KywsTKdPn7ZrO336tAIDAxUQEJDva/z8/OTn51cc5QEAAKCYmWpkNjo6Whs2bLBrW79+vaKjo91UEQAAANzJrWE2JSVFCQkJSkhIkPT30lsJCQk6duyYpL+nCAwcONDW/7HHHtOhQ4f0/PPPa8+ePZo1a5Y++eQTPfPMM+4oHwAAAG7m1jC7Y8cONW3aVE2bNpUkxcbGqmnTphozZowk6dSpU7ZgK0nVqlXT559/rvXr16tJkyZ6++239X//938sywUAAOCh3Dpntn379jIMo8Dt+d3dq3379vrpp59cWBUAAADMwlRzZgEAAIArEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpmeoOYEBxOX36tJKSklyy7/T0dCUmJrpk3+4QFhbm0rvsWa1WhYaGumz/AABzI8wCVzl9+rQeeHCgMjPS3V0KJPn4+mnhgg8JtACAfBFmgaskJSUpMyNdqdXbKcffWvQHyMmSV3pK0e/XTXL8yklervlV4pWWJB3arKSkJMIsACBfhFmgADn+VuWUreSafZd3yW4BAPA4hFkAHo850o5jjjSAkoYwC8CjMUe6ZGGONABnEWYBeDTmSDuHOdIAShrCLACIOdKehGkljmNaCcyAMAsA8BhMKylZmFaCokCYBQB4DKaVOKc0TCthJN5xZh2JJ8wCADwO00o8AyPxJYurRuIJswAAoFRiJN45Zh2JJ8wCAIBSjZH40s3L3QUAAAAA14swCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMq4+4CzMQr9YK7S/B4nAMAAHAlwqwTAg5vcXcJAAAAuAJh1gmp1doqJ6CCu8vwaF6pF3hTAQAAbAizTsgJqKCcspXcXQYAAAD+f4RZJ3ilJbm7BI/HOQAAAFcizDrAarXKx9dPOrTZ3aVAko+vn6xWq7vLAAAAJQBh1gGhoaFauOBDJSWZd1Tw6NGjmjBhgkaNGqWqVau6u5x/xGq1KjQ01N1lAACAEoAw66DQ0NBSEaCqVq2q2rVru7sMAACAIsFNEwAAAGBahFkAAACYFmEWAAAApkWYBQAAgGlxAVgJkJaWpmPHjrn0GEePHrX715WioqLk7+/v8uMAAAAQZkuAY8eOaejQocVyrAkTJrj8GHFxcayYAAAAigVhtgSIiopSXFycu8soMlFRUe4uAQAAeAjCbAng7+/PSCYAAMB14AIwAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmFYZdxcAlFReqRfcXYLH4xwAAK6FMAsUIODwFneXAAAAroEwCxQgtVpb5QRUcHcZHs0r9QJvKgAAhSLMAgXICaignLKV3F0GAAAoBBeAAQAAwLQIswAAADAtwiwAAABMizmzQAG80pLcXYLH4xwAAK6FMAtcxWq1ysfXTzq02d2lQJKPr5+sVqu7ywAAlFCEWeAqoaGhWrjgQyUlmXdU8OjRo5owYYJGjRqlqlWrurucf8RqtSo0NNTdZQAASijCLJCP0NDQUhGgqlatqtq1a7u7DAAAXIYwCwDi1rklAecAwPUgzAKAuH0xAJgVYRYoZmlpaTp27JhLj3H06FG7f10pKipK/v7+Lj+Oq3H7Yvfj9sUArgdhFihmx44d09ChQ4vlWBMmTHD5MeLi4krFvFxuXwwA5kSYBYpZVFSU4uLi3F1GkYmKinJ3CQAAD0aYBYqZv79/qRjJBACgJCDMAoC421hJUJzngJUT3I9zgKJCmAXg0bjjW8lSXHd840IzoPQgzALwaNzxrWQprju+sXqF+7F6BYoKYRaAx+OOb56H1SuA0oMwCwAASjXm57qfK88BYRYAXIibZJRMXPDnfsV5DpjOULoRZgHAhbhJRsnCBX8lS3Fd8Mccafdz5RxpwiwAuBA3yShZuOCvZCmuC/6YI126lYgwO3PmTL311ltKTExUkyZNNGPGDLVs2TLfvvHx8RoyZIhdm5+fn9LS0oqjVABwCjfJKHm44M/zMK3E/Vx5DtweZj/++GPFxsZqzpw5atWqlaZNm6ZOnTpp7969CgkJyfc1gYGB2rt3r+25xWIprnIBACgQc6RLFqaVlCyumlZiMQzDKPK9OqFVq1Zq0aKF3nvvPUlSTk6OIiMj9dRTT+nFF1/M0z8+Pl4jR47UhQsXrut4ycnJslqtSkpKUmBg4D8pHQAAO/v27Su2OdLFwexzpCXp9OnTTCspIZyZVuJMXnPryGxGRoZ+/PFHvfTSS7Y2Ly8vdezYUdu2bSvwdSkpKapatapycnJ0yy23aOLEiWrQoEG+fdPT05Wenm57npycXHSfAAAAV2COdMnjymklxTESX5zMOhLv1jD7559/Kjs7O883WWhoqPbs2ZPva+rUqaN58+apcePGSkpK0pQpU9S6dWv9+uuvqlKlSp7+kyZN0rhx41xSPwAAV2KOtGdhtZKSwe1zZp0VHR2t6Oho2/PWrVurXr16mjt3rsaPH5+n/0svvaTY2Fjb8+TkZEVGRhZLrQAAoPRiJL5kcGuYrVSpkry9vXX69Gm79tOnTyssLMyhffj4+Khp06Y6cOBAvtv9/Pzk5+f3j2sFAAC4EiPxJYOXOw/u6+urZs2aacOGDba2nJwcbdiwwW70tTDZ2dn65ZdfFB4e7qoyAQAAUEK5fZpBbGysBg0apObNm6tly5aaNm2aLl26ZFtLduDAgbrxxhs1adIkSdJrr72mW2+9VTVr1tSFCxf01ltv6ejRo3rkkUfc+WkAAADADdweZvv27auzZ89qzJgxSkxM1M0336y1a9faLgo7duyYvLz+3wDyX3/9pUcffVSJiYmqWLGimjVrpm+//Vb169d316cAAAAAN3H7OrPFjXVmAQAASjZn8ppb58wCAAAA/wRhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmFYZdxdQ3AzDkCQlJye7uRIAAADkJzen5ea2wnhcmL148aIkKTIy0s2VAAAAoDAXL16U1WottI/FcCTyliI5OTk6efKkypcvL4vF4u5yik1ycrIiIyN1/PhxBQYGurscuBjn27Nwvj0L59uzeOr5NgxDFy9eVEREhLy8Cp8V63Ejs15eXqpSpYq7y3CbwMBAj/ph8HScb8/C+fYsnG/P4onn+1ojsrm4AAwAAACmRZgFAACAaRFmPYSfn5/Gjh0rPz8/d5eCYsD59iycb8/C+fYsnO9r87gLwAAAAFB6MDILAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizDrYd544w1ZLBaNHDnS3aXARf744w898MADCg4OVkBAgBo1aqQdO3a4uyy4QHZ2tkaPHq1q1aopICBANWrU0Pjx4x26lzlKvi1btqhbt26KiIiQxWLRihUr7LYbhqExY8YoPDxcAQEB6tixo/bv3++eYvGPFXa+MzMz9cILL6hRo0YqW7asIiIiNHDgQJ08edJ9BZcghFkPsn37ds2dO1eNGzd2dylwkb/++ktt2rSRj4+P1qxZo99++01vv/22Klas6O7S4AKTJ0/W7Nmz9d577+n333/X5MmT9eabb2rGjBnuLg1F4NKlS2rSpIlmzpyZ7/Y333xT7777rubMmaPvv/9eZcuWVadOnZSWllbMlaIoFHa+L1++rJ07d2r06NHauXOnli9frr1796p79+5uqLTkYWkuD5GSkqJbbrlFs2bN0uuvv66bb75Z06ZNc3dZKGIvvviitm7dqq+//trdpaAYdO3aVaGhofrggw9sbffdd58CAgK0cOFCN1aGomaxWPTpp5+qR48ekv4elY2IiNCzzz6rf//735KkpKQkhYaGKj4+Xv369XNjtfinrj7f+dm+fbtatmypo0ePKioqqviKK4EYmfUQw4cPV5cuXdSxY0d3lwIX+uyzz9S8eXP17t1bISEhatq0qd5//313lwUXad26tTZs2KB9+/ZJkn7++Wd98803iomJcXNlcLXDhw8rMTHR7ne61WpVq1attG3bNjdWhuKSlJQki8WiChUquLsUtyvj7gLgeh999JF27typ7du3u7sUuNihQ4c0e/ZsxcbG6uWXX9b27ds1YsQI+fr6atCgQe4uD0XsxRdfVHJysurWrStvb29lZ2drwoQJGjBggLtLg4slJiZKkkJDQ+3aQ0NDbdtQeqWlpemFF17Q/fffr8DAQHeX43aE2VLu+PHjevrpp7V+/Xr5+/u7uxy4WE5Ojpo3b66JEydKkpo2bardu3drzpw5hNlS6JNPPtGiRYu0ePFiNWjQQAkJCRo5cqQiIiI430AplZmZqT59+sgwDM2ePdvd5ZQITDMo5X788UedOXNGt9xyi8qUKaMyZcpo8+bNevfdd1WmTBllZ2e7u0QUofDwcNWvX9+urV69ejp27JibKoIrPffcc3rxxRfVr18/NWrUSA8++KCeeeYZTZo0yd2lwcXCwsIkSadPn7ZrP336tG0bSp/cIHv06FGtX7+eUdn/H2G2lOvQoYN++eUXJSQk2B7NmzfXgAEDlJCQIG9vb3eXiCLUpk0b7d27165t3759qlq1qpsqgitdvnxZXl72v8a9vb2Vk5PjpopQXKpVq6awsDBt2LDB1pacnKzvv/9e0dHRbqwMrpIbZPfv368vv/xSwcHB7i6pxGCaQSlXvnx5NWzY0K6tbNmyCg4OztMO83vmmWfUunVrTZw4UX369NEPP/yguLg4xcXFubs0uEC3bt00YcIERUVFqUGDBvrpp580depUPfTQQ+4uDUUgJSVFBw4csD0/fPiwEhISFBQUpKioKI0cOVKvv/66atWqpWrVqmn06NGKiIgo9Ap4lFyFne/w8HD16tVLO3fu1OrVq5WdnW2bGx0UFCRfX193lV0yGPA47dq1M55++ml3lwEXWbVqldGwYUPDz8/PqFu3rhEXF+fukuAiycnJxtNPP21ERUUZ/v7+RvXq1Y1Ro0YZ6enp7i4NRWDjxo2GpDyPQYMGGYZhGDk5Ocbo0aON0NBQw8/Pz+jQoYOxd+9e9xaN61bY+T58+HC+2yQZGzdudHfpbsc6swAAADAt5swCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCQCkUHx+vChUqFMuxBg8ezC1UAbgNYRYA4JAjR47IYrEoISHB3aUAgA1hFgAAAKZFmAUAJ7Vv315PPfWURo4cqYoVKyo0NFTvv/++Ll26pCFDhqh8+fKqWbOm1qxZI0nKzs7Www8/rGrVqikgIEB16tTR9OnTbftLS0tTgwYNNHToUFvbwYMHVb58ec2bN8+hmuLj4xUVFaUbbrhB9957r86dO5enz8qVK3XLLbfI399f1atX17hx45SVlWXbbrFYNHv2bMXExCggIEDVq1fXsmXLbNurVasmSWratKksFovat29vt/8pU6YoPDxcwcHBGj58uDIzMx2qHQD+EQMA4JR27doZ5cuXN8aPH2/s27fPGD9+vOHt7W3ExMQYcXFxxr59+4zHH3/cCA4ONi5dumRkZGQYY8aMMbZv324cOnTIWLhwoXHDDTcYH3/8sW2fP/30k+Hr62usWLHCyMrKMm699Vbj3nvvdaie7777zvDy8jImT55s7N2715g+fbpRoUIFw2q12vps2bLFCAwMNOLj442DBw8aX3zxhXHTTTcZr776qq2PJCM4ONh4//33jb179xqvvPKK4e3tbfz222+GYRjGDz/8YEgyvvzyS+PUqVPGuXPnDMMwjEGDBhmBgYHGY489Zvz+++/GqlWrjBtuuMGIi4srgq82ABSOMAsATmrXrp1x22232Z5nZWUZZcuWNR588EFb26lTpwxJxrZt2/Ldx/Dhw4377rvPru3NN980KlWqZDz55JNGeHi48eeffzpUz/3332/cc889dm19+/a1C7MdOnQwJk6caNdnwYIFRnh4uO25JOOxxx6z69OqVSvj8ccfNwzDMA4fPmxIMn766Se7PoMGDTKqVq1qZGVl2dp69+5t9O3b16H6AeCfYJoBAFyHxo0b2z729vZWcHCwGjVqZGsLDQ2VJJ05c0aSNHPmTDVr1kyVK1dWuXLlFBcXp2PHjtnt89lnn1Xt2rX13nvvad68eQoODnaolt9//12tWrWya4uOjrZ7/vPPP+u1115TuXLlbI9HH31Up06d0uXLlwt8XXR0tH7//fdr1tCgQQN5e3vbnoeHh9s+dwBwpTLuLgAAzMjHx8fuucVisWuzWCySpJycHH300Uf697//rbffflvR0dEqX7683nrrLX3//fd2+zhz5oz27dsnb29v7d+/X507dy6yelNSUjRu3Dj17NkzzzZ/f/9/vP/8vh45OTn/eL8AcC2EWQBwsa1bt6p169Z64oknbG0HDx7M0++hhx5So0aN9PDDD+vRRx9Vx44dVa9evWvuv169enmC8XfffWf3/JZbbtHevXtVs2bNQvf13XffaeDAgXbPmzZtKkny9fWV9PcFbQBQUhBmAcDFatWqpQ8//FDr1q1TtWrVtGDBAm3fvt22OoD09zSEbdu2adeuXYqMjNTnn3+uAQMG6LvvvrOFyIKMGDFCbdq00ZQpU/Svf/1L69at09q1a+36jBkzRl27dlVUVJR69eolLy8v/fzzz9q9e7def/11W7+lS5eqefPmuu2227Ro0SL98MMP+uCDDyRJISEhCggI0Nq1a1WlShX5+/vLarUW4VcKAJzHnFkAcLFhw4apZ8+e6tu3r1q1aqVz587ZjdLu2bNHzz33nGbNmqXIyEhJ0qxZs/Tnn39q9OjR19z/rbfeqvfff1/Tp09XkyZN9MUXX+iVV16x69OpUyetXr1aX3zxhVq0aKFbb71V77zzjqpWrWrXb9y4cfroo4/UuHFjffjhh1qyZInq168vSSpTpozeffddzZ07VxEREfrXv/71T780APCPWQzDMNxdBADA/SwWiz799FNuTQvAVBiZBQAAgGkRZgGghIuJibFbUuvKx8SJE91dHgC4FdMMAKCE++OPP5SamprvtqCgIAUFBRVzRQBQchBmAQAAYFpMMwAAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmNb/BxYg8dOyITZjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Load hyperparameter search results\n",
    "results_df = pd.read_csv(\"../data/processed/xgb_hyperparam_results.csv\")\n",
    "\n",
    "# Show top 10 parameter sets with lowest validation RMSLE\n",
    "top_results = results_df.nsmallest(10, 'validation_rmsle')\n",
    "print(\"Top 10 parameter sets with lowest validation RMSLE:\")\n",
    "print(top_results)\n",
    "\n",
    "# Plot validation RMSLE across all parameter sets\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(results_df['validation_rmsle'].values)\n",
    "plt.title('XGBoost Validation RMSLE across all parameter sets')\n",
    "plt.xlabel('Parameter Set Index')\n",
    "plt.ylabel('Validation RMSLE')\n",
    "plt.show()\n",
    "\n",
    "# Visualize RMSLE by max_depth\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x='max_depth', y='validation_rmsle', data=results_df)\n",
    "plt.title('Validation RMSLE by max_depth')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Validation RMSLE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c9c07",
   "metadata": {},
   "source": [
    "### Focused, Randomized Hyperparameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b17fd",
   "metadata": {},
   "source": [
    "\n",
    "The initial grid search for XGBoost focused on the main structure and learning parameters: `max_depth`, `n_estimators`, `learning_rate`, `subsample`, and `colsample_bytree`. This extensive search revealed several clear trends:\n",
    "\n",
    "- **Max Depth:** All top-performing models leveraged the deepest tested trees (`max_depth=12`). The boxplot analysis shows that increasing `max_depth` consistently reduces the median validation RMSLE, indicating that the model benefits from additional complexityâ€”likely due to the datasetâ€™s rich features and size. However, improvement begins to plateau as depth increases, and there remains significant performance variability within each group.\n",
    "- **Learning Rate & Estimators:** The best results were achieved with a lower learning rate (`0.05`) paired with a higher number of estimators (`200`), supporting gradual, robust learning and better generalization.\n",
    "- **Subsample & Colsample_bytree:** Higher values (0.8 or 1.0) for both were common among top models, suggesting that including more data and features per tree helps reduce variance and boosts robustness.\n",
    "- **Variance:** Despite these trends, outliers exist at every depth and configuration, underscoring that tuning multiple parameters together is essential for consistent performance.\n",
    "\n",
    "**Limitation Identified:**  \n",
    "While the initial grid search provided valuable insights, it did **not** fully explore key regularization parameters such as `min_child_weight`, `gamma`, `reg_alpha`, and `reg_lambda`. These parameters can play a major role in controlling overfitting and further improving generalization.\n",
    "\n",
    "**Next Steps:**  \n",
    "To address this and further refine the model, I will perform a **focused, randomized hyperparameter search**:\n",
    "- Concentrating on the most promising tree depths and learning rates identified previously.\n",
    "- Including all major regularization parameters for a more comprehensive evaluation.\n",
    "- Using random sampling to efficiently explore the expanded hyperparameter space and manage computational cost.\n",
    "\n",
    "The results from this refined search will be saved to a new CSV, which can found here [`../data/processed/xgb_hyperparam_random_seach.csv`](../data/processed/xgb_hyperparam_random_search.csv) and used for the final model evaluation and comparison in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee380149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.1, min_child_weight=10, gamma=0, reg_alpha=0, reg_lambda=1.0\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05, min_child_weight=10, gamma=0.1, reg_alpha=0, reg_lambda=1.0\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.1, min_child_weight=1, gamma=0.1, reg_alpha=1.0, reg_lambda=1.0\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05, min_child_weight=10, gamma=0.1, reg_alpha=0, reg_lambda=2.0\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05, min_child_weight=5, gamma=0, reg_alpha=0.1, reg_lambda=1.0\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.1, min_child_weight=10, gamma=0.1, reg_alpha=0, reg_lambda=2.0\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05, min_child_weight=5, gamma=0.1, reg_alpha=1.0, reg_lambda=2.0\n",
      "Testing: max_depth=16, n_estimators=200, learning_rate=0.1, min_child_weight=1, gamma=0, reg_alpha=0, reg_lambda=2.0\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05, min_child_weight=10, gamma=0.1, reg_alpha=0.1, reg_lambda=1.0\n",
      "Testing: max_depth=16, n_estimators=100, learning_rate=0.05, min_child_weight=1, gamma=0, reg_alpha=0, reg_lambda=1.0\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05, min_child_weight=5, gamma=0.1, reg_alpha=1.0, reg_lambda=1.0\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05, min_child_weight=5, gamma=0, reg_alpha=0.1, reg_lambda=1.0\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05, min_child_weight=5, gamma=0.1, reg_alpha=1.0, reg_lambda=2.0\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05, min_child_weight=10, gamma=0.1, reg_alpha=0, reg_lambda=2.0\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05, min_child_weight=5, gamma=0, reg_alpha=1.0, reg_lambda=1.0\n",
      "Testing: max_depth=16, n_estimators=200, learning_rate=0.05, min_child_weight=5, gamma=0, reg_alpha=1.0, reg_lambda=2.0\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05, min_child_weight=1, gamma=0, reg_alpha=0, reg_lambda=1.0\n",
      "Testing: max_depth=16, n_estimators=200, learning_rate=0.1, min_child_weight=10, gamma=0.1, reg_alpha=0, reg_lambda=1.0\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.1, min_child_weight=5, gamma=0.1, reg_alpha=1.0, reg_lambda=1.0\n",
      "Testing: max_depth=16, n_estimators=200, learning_rate=0.1, min_child_weight=1, gamma=0, reg_alpha=0, reg_lambda=1.0\n",
      "Testing: max_depth=14, n_estimators=200, learning_rate=0.1, min_child_weight=10, gamma=0, reg_alpha=0.1, reg_lambda=1.0\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05, min_child_weight=1, gamma=0, reg_alpha=0.1, reg_lambda=1.0\n",
      "Testing: max_depth=16, n_estimators=100, learning_rate=0.05, min_child_weight=1, gamma=0, reg_alpha=0.1, reg_lambda=2.0\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.1, min_child_weight=5, gamma=0.1, reg_alpha=1.0, reg_lambda=2.0\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.05, min_child_weight=10, gamma=0, reg_alpha=0.1, reg_lambda=1.0\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.05, min_child_weight=1, gamma=0, reg_alpha=1.0, reg_lambda=2.0\n",
      "Testing: max_depth=16, n_estimators=100, learning_rate=0.05, min_child_weight=1, gamma=0, reg_alpha=0.1, reg_lambda=2.0\n",
      "Testing: max_depth=14, n_estimators=100, learning_rate=0.1, min_child_weight=10, gamma=0, reg_alpha=0, reg_lambda=2.0\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.1, min_child_weight=5, gamma=0.1, reg_alpha=1.0, reg_lambda=1.0\n",
      "Testing: max_depth=12, n_estimators=100, learning_rate=0.05, min_child_weight=10, gamma=0, reg_alpha=0, reg_lambda=1.0\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.05, min_child_weight=5, gamma=0, reg_alpha=1.0, reg_lambda=2.0\n",
      "Testing: max_depth=14, n_estimators=100, learning_rate=0.1, min_child_weight=1, gamma=0.1, reg_alpha=1.0, reg_lambda=1.0\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05, min_child_weight=5, gamma=0.1, reg_alpha=1.0, reg_lambda=1.0\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05, min_child_weight=5, gamma=0.1, reg_alpha=0, reg_lambda=2.0\n",
      "Testing: max_depth=14, n_estimators=200, learning_rate=0.05, min_child_weight=1, gamma=0.1, reg_alpha=0.1, reg_lambda=1.0\n",
      "Testing: max_depth=10, n_estimators=200, learning_rate=0.05, min_child_weight=1, gamma=0, reg_alpha=0, reg_lambda=1.0\n",
      "Testing: max_depth=14, n_estimators=200, learning_rate=0.05, min_child_weight=10, gamma=0.1, reg_alpha=0, reg_lambda=1.0\n",
      "Testing: max_depth=14, n_estimators=100, learning_rate=0.1, min_child_weight=1, gamma=0, reg_alpha=1.0, reg_lambda=1.0\n",
      "Testing: max_depth=12, n_estimators=200, learning_rate=0.1, min_child_weight=1, gamma=0, reg_alpha=0.1, reg_lambda=2.0\n",
      "Testing: max_depth=10, n_estimators=100, learning_rate=0.1, min_child_weight=10, gamma=0.1, reg_alpha=0.1, reg_lambda=2.0\n",
      "   max_depth  n_estimators  learning_rate  subsample  colsample_bytree  \\\n",
      "0         14           200           0.05        1.0               1.0   \n",
      "1         16           200           0.05        0.8               1.0   \n",
      "2         14           200           0.05        0.8               0.8   \n",
      "3         14           100           0.10        1.0               1.0   \n",
      "4         16           200           0.10        1.0               1.0   \n",
      "\n",
      "   min_child_weight  gamma  reg_alpha  reg_lambda  validation_rmsle  \n",
      "0                 1    0.1        0.1         1.0          0.492857  \n",
      "1                 5    0.0        1.0         2.0          0.492890  \n",
      "2                10    0.1        0.0         1.0          0.495148  \n",
      "3                 1    0.0        1.0         1.0          0.495159  \n",
      "4                10    0.1        0.0         1.0          0.495175  \n",
      "Randomized search results saved to ../data/processed/xgb_hyperparam_random_search.csv\n"
     ]
    }
   ],
   "source": [
    "# Focused, randomized hyperparameter search\n",
    "\n",
    "import random\n",
    "from itertools import product\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [10, 12, 14, 16],            \n",
    "    'n_estimators': [100, 200],               \n",
    "    'learning_rate': [0.05, 0.1],             \n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'gamma': [0, 0.1],\n",
    "    'reg_alpha': [0, 0.1, 1.0],\n",
    "    'reg_lambda': [1.0, 2.0]\n",
    "}\n",
    "\n",
    "# Create all combinations, then randomly sample N\n",
    "all_combos = list(product(\n",
    "    param_grid['max_depth'],\n",
    "    param_grid['n_estimators'],\n",
    "    param_grid['learning_rate'],\n",
    "    param_grid['subsample'],\n",
    "    param_grid['colsample_bytree'],\n",
    "    param_grid['min_child_weight'],\n",
    "    param_grid['gamma'],\n",
    "    param_grid['reg_alpha'],\n",
    "    param_grid['reg_lambda'],\n",
    "))\n",
    "random.seed(RANDOM_SEED)\n",
    "# Try 40 random combos\n",
    "sampled_combos = random.sample(all_combos, k=40) \n",
    "\n",
    "results = []\n",
    "\n",
    "for params in sampled_combos:\n",
    "    max_depth, n_estimators, learning_rate, subsample, colsample_bytree, min_child_weight, gamma, reg_alpha, reg_lambda = params\n",
    "    print(f\"Testing: max_depth={max_depth}, n_estimators={n_estimators}, learning_rate={learning_rate}, min_child_weight={min_child_weight}, gamma={gamma}, reg_alpha={reg_alpha}, reg_lambda={reg_lambda}\")\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        min_child_weight=min_child_weight,\n",
    "        gamma=gamma,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        random_state=RANDOM_SEED,\n",
    "        tree_method='hist',\n",
    "        verbosity=0\n",
    "    )\n",
    "    xgb.fit(X_train, y_train, verbose=False)\n",
    "    preds = xgb.predict(X_valid)\n",
    "    preds = np.clip(preds, 0, None)\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_valid, preds))\n",
    "    results.append({\n",
    "        'max_depth': max_depth,\n",
    "        'n_estimators': n_estimators,\n",
    "        'learning_rate': learning_rate,\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'min_child_weight': min_child_weight,\n",
    "        'gamma': gamma,\n",
    "        'reg_alpha': reg_alpha,\n",
    "        'reg_lambda': reg_lambda,\n",
    "        'validation_rmsle': rmsle\n",
    "    })\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results).sort_values('validation_rmsle').reset_index(drop=True)\n",
    "print(results_df.head())\n",
    "results_df.to_csv(\"../data/processed/xgb_hyperparam_random_search.csv\", index=False)\n",
    "print(\"Randomized search results saved to ../data/processed/xgb_hyperparam_random_search.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f7577e",
   "metadata": {},
   "source": [
    "#### Validation & RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b885af80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth  n_estimators  learning_rate  subsample  colsample_bytree  \\\n",
      "0         14           200           0.05        1.0               1.0   \n",
      "1         16           200           0.05        0.8               1.0   \n",
      "2         14           200           0.05        0.8               0.8   \n",
      "3         14           100           0.10        1.0               1.0   \n",
      "4         16           200           0.10        1.0               1.0   \n",
      "5         14           100           0.10        1.0               0.8   \n",
      "6         14           200           0.10        1.0               1.0   \n",
      "7         16           200           0.10        1.0               0.8   \n",
      "8         16           200           0.10        1.0               0.8   \n",
      "9         12           200           0.05        1.0               0.8   \n",
      "\n",
      "   min_child_weight  gamma  reg_alpha  reg_lambda  validation_rmsle  \n",
      "0                 1    0.1        0.1         1.0          0.492857  \n",
      "1                 5    0.0        1.0         2.0          0.492890  \n",
      "2                10    0.1        0.0         1.0          0.495148  \n",
      "3                 1    0.0        1.0         1.0          0.495159  \n",
      "4                10    0.1        0.0         1.0          0.495175  \n",
      "5                10    0.0        0.0         2.0          0.496953  \n",
      "6                10    0.0        0.1         1.0          0.497711  \n",
      "7                 1    0.0        0.0         2.0          0.497801  \n",
      "8                 1    0.0        0.0         1.0          0.498083  \n",
      "9                 5    0.0        1.0         1.0          0.499723  \n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Load hyperparameter search results\n",
    "results_df = pd.read_csv(\"../data/processed/xgb_hyperparam_random_search.csv\")\n",
    "\n",
    "# Show top 10 parameter sets with lowest validation RMSLE\n",
    "top_results = results_df.nsmallest(10, 'validation_rmsle')\n",
    "print(top_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0883554",
   "metadata": {},
   "source": [
    "##### Final XGBoost Hyperparameter Search Results\n",
    "\n",
    "The expanded, randomized hyperparameter search included all major structure and regularization parameters.  \n",
    "The top 10 models now span both `max_depth=14` and `16`, confirming that, with appropriate regularization, deeper trees can further improve performance on this dataset.  \n",
    "Strong regularizationâ€”through adjustments to `min_child_weight`, `gamma`, `reg_alpha`, and `reg_lambda`â€”is key to preventing overfitting at high depths, and the best results arise from a balance of these parameters.  \n",
    "Validation RMSLE is now even lower, and the tight spread among the top models suggests the results are robust and generalizable.\n",
    "\n",
    "These results provide a strong basis for final model selection and comparison in the evaluation phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c1cf4",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b780de26",
   "metadata": {},
   "source": [
    "In this notebook, I developed, tuned, and benchmarked two advanced modeling approaches for the sales forecasting task: Prophet and XGBoost. The modeling workflow followed a robust chronological train/validation split and included systematic hyperparameter optimization.\n",
    "\n",
    "Key findings:\n",
    "- **XGBoost** achieved its best performance with deeper trees (`max_depth=14` and above) when paired with strong regularization. The final, focused hyperparameter search delivered the lowest validation RMSLE of the project so far, confirming the importance of both model complexity and effective overfitting control.\n",
    "- **Prophet** established a solid time series baseline, capturing overall trends and seasonality across stores and product families.\n",
    "\n",
    "All results, including detailed validation metrics and predictions, have been exported to CSV files for full transparency and reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the next notebook (`04_model_evaluation.ipynb`), I will:\n",
    "\n",
    "- **Conduct a thorough, side-by-side evaluation** of all models (naive baseline, Prophet, and XGBoost) using the results exported in this notebook.\n",
    "- **Analyze performance across segments** (e.g., by store, product family, time period) to identify strengths and weaknesses of each approach.\n",
    "- **Visualize and interpret model predictions** to assess business relevance and forecast reliability.\n",
    "- **Justify final model selection** using statistical and business criteria.\n",
    "- **Provide actionable recommendations** for potential deployment and future model improvements.\n",
    "\n",
    "This structured evaluation will ensure that the chosen forecasting solution is not only the most accurate, but also robust, interpretable, and suited to the business context.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
